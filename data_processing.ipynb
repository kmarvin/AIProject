{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- encoding: iso-8859-15 -*-\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Import other python files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration / parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_config(config_path = \"config.txt\", args = dict()):\n",
    "    with open(config_path) as source:\n",
    "        for line in source:\n",
    "            line = line.strip()\n",
    "            argLong, valueLong = line.split('=')\n",
    "            arg = argLong.strip()\n",
    "            value = valueLong.strip()\n",
    "            if value == 'True':\n",
    "                value = True\n",
    "            elif value == 'False':\n",
    "                value = False\n",
    "            elif '.' in value:\n",
    "                value = float(value)\n",
    "            else:\n",
    "                value = int(value)\n",
    "            args[arg] = value\n",
    "    return edict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'cuda': False, 'batch_size': 81, 'seq_len': 30, 'clip': 50, 'lr': 0.01, 'num_layers': 3, 'offset': 4}\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(textsource):\n",
    "    text = ''\n",
    "    with open(textsource, encoding=\"utf8\") as txtsource:\n",
    "        for line in txtsource:\n",
    "            line = line.strip().lower()\n",
    "            line = line.replace(',', '').replace('.', '')\n",
    "            line = line.replace('»', '').replace('«', '')\n",
    "            line = line.replace('\"', '')\n",
    "            line = line.replace(u'\\ufeff', '')\n",
    "            text += ' ' + line\n",
    "    text = text[:1000] #### nachher wieder rauslöschen!!!\n",
    "    return text\n",
    "# Chevrons müssen noch weg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_len, offset):\n",
    "    # Get all the unique characters appearing in the text \n",
    "    chars = sorted(list(set(text)))\n",
    "    char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "    print(char_idx)\n",
    "    print(len(char_idx))\n",
    "    idx_char = dict((i, c) for i, c in enumerate(chars)) #### das brauchen wir später!!!\n",
    "    no_classes = len(chars) # the nr. of unique characters corresponds to the nr. of classes\n",
    "    \n",
    "    # Define training samples by splitting the text\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - seq_len, offset):\n",
    "        sentences.append(text[i: i + seq_len])\n",
    "        next_chars.append(text[i + seq_len])\n",
    "    print('nr training samples', len(sentences))\n",
    "    \n",
    "    # Generate features and labels using one-hot encoding\n",
    "    X = np.zeros((len(sentences), seq_len, len(chars)), dtype='f')\n",
    "    y = np.zeros((len(sentences)))\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for j, char in enumerate(sentence):\n",
    "            X[i, j, char_idx[char]] = 1\n",
    "        y[i] = char_idx[next_chars[i]]\n",
    "        \n",
    "    return X, y, char_idx, idx_char, no_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    ''' A text dataset class which implements the abstract class torch.utils.data.Dataset. '''\n",
    "    def __init__(self, text, seq_len, offset):\n",
    "        self.data, self.target, self.char_idx, self.idx_char, self.no_classes = prepare_data(text, seq_len, offset)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ''' Get the data for one training sample (by index) '''\n",
    "        return self.data[index,:,:], self.target[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' Get the number of training samples '''\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, no_classes):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = no_classes, hidden_size = args.hidden_size, num_layers = 3)\n",
    "        self.linear = nn.Linear(in_features = args.hidden_size, out_features = no_classes)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        self.linear.weight.data.normal_(0, 0.075**2)\n",
    "        self.linear.bias.data.normal_(0, 0.075**2)\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.xavier_normal(param) \n",
    "        nn.init.xavier_uniform(self.lstm.weight_hh_l0)\n",
    "\n",
    "        \n",
    "        # LSTM needs hidden variable which is initialized in self.init_hidden(self)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         m.weight.data.normal_(0, 0.075*0.075)\n",
    "        #         m.bias.data.normal_(0, 0.075*0.075)\n",
    "                \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        c0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        return (h0, c0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = x.type(torch.DoubleTensor)\n",
    "        #print(x)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden) # (h0, c0 are set to default values)\n",
    "        #print(\"LSTM_OUT:\")\n",
    "        #print(lstm_out)\n",
    "        lstm_out = lstm_out.view(-1, lstm_out.size(2))\n",
    "        #print(\"----------------\")\n",
    "        #print(lstm_out)\n",
    "        linear_out = self.linear(lstm_out[-1])\n",
    "        #print(\"Linear_OUT:\")\n",
    "        #print(linear_out)\n",
    "        res = self.softmax(linear_out) # use only the output of the last layer of lstm\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training loop (one epoch)\n",
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        print(\"data:\")\n",
    "        print(data)\n",
    "        print(\"target:\")\n",
    "        print(target)\n",
    "        data = data.view(data.size(1), data.size(0), data.size(2))\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        print(\"output:\")\n",
    "        print(output)\n",
    "        loss = criterion(output.unsqueeze_(0), target.long()) # check how far away the output is from the original data\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data[0]\n",
    "        #print(total_loss)\n",
    "\n",
    "\n",
    "    relative_loss = total_loss/float(len(train_loader))\n",
    "    print('Relative loss over epoch %s: %s' %(epoch, relative_loss))\n",
    "    return relative_loss # return the relative loss for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction loop for ONE testdata tensor\n",
    "def rnn_predict(model, testdata):\n",
    "    ''' Note: testdata have to be submitted as a tensor'''\n",
    "    testdata = torch.from_numpy(testdata)\n",
    "    print(\"testdata:\")\n",
    "    print(testdata)\n",
    "    model.eval()\n",
    "    testdata = testdata.view(testdata.size(0), -1)\n",
    "    if args.cuda:\n",
    "        testdata = testdata.cuda()\n",
    "    testdata = testdata.type(torch.FloatTensor)\n",
    "    testdata = Variable(testdata)\n",
    "    prediction = model(testdata)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Function that returns the largest factor of number that isn't the number itself '''\n",
    "def lfactor(num):\n",
    "    for i in range(num - 1, 0, -1): # go backwards from num - 1 to 1\n",
    "        if num % i == 0:            # if a number divides evenly\n",
    "            return i                # it's the largest factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marvins test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# die funktion brauchen wir vllt gar nicht, je nachdem ob wir den test loader verwenden oder wie wir das auch immer machen\n",
    "def prepare_input(text):\n",
    "    X = np.zeros((1, args.seq_len, no_classes))  # array with one entry which have 20 lines, each 11 entrys\n",
    "    for t, char in enumerate(text):\n",
    "        X[0, t, char_idx[char]] = 1.\n",
    "    return X\n",
    "\n",
    "def sample(preds, top_n=1):\n",
    "    print(\"test\")\n",
    "    preds = preds.data.numpy()[0]\n",
    "    print(preds)\n",
    "    print(preds.shape)\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
    "\n",
    "\n",
    "def predict_completion(model, text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    next_char = ''\n",
    "    max_iterations = 30\n",
    "    i = 0\n",
    "    while next_char != ' ' and i < max_iterations:\n",
    "        i += 1\n",
    "        x = prepare_input(text)\n",
    "        preds = rnn_predict(model, x)\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = idx_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "\n",
    "    return completion\n",
    "\n",
    "\n",
    "def predict_completions(model, text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.rnn_predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [idx_char[idx] + predict_completion(text[1:] + idx_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ö': 26, 'c': 3, 'd': 4, 'j': 10, 'g': 7, 'p': 16, 'l': 12, 'e': 5, 'r': 17, 'b': 2, 't': 19, 'f': 6, 'ü': 27, ' ': 0, 'u': 20, 'z': 23, 'v': 21, 'k': 11, 'w': 22, 'ß': 24, 'o': 15, 'n': 14, 'ä': 25, 'i': 9, 'h': 8, 's': 18, '–': 28, 'm': 13, 'a': 1}\n",
      "29\n",
      "nr training samples 243\n",
      "{'ö': 26, 'c': 3, 'd': 4, 'j': 10, 'g': 7, 'p': 16, 'l': 12, 'e': 5, 'r': 17, 'b': 2, 't': 19, 'f': 6, 'ü': 27, ' ': 0, 'u': 20, 'z': 23, 'v': 21, 'k': 11, 'w': 22, 'ß': 24, 'o': 15, 'n': 14, 'ä': 25, 'i': 9, 'h': 8, 's': 18, '–': 28, 'm': 13, 'a': 1}\n",
      "29\n",
      "nr training samples 243\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "# Generate train and test loader from our data\n",
    "train_text = prepare_text('./Brown_Leseprobe.txt')\n",
    "train_set = TextDataset(train_text, args.seq_len, args.offset)\n",
    "args.batch_size = lfactor(len(train_set))\n",
    "train_loader = DataLoader(train_set, batch_size = args.batch_size, shuffle=True)\n",
    "\n",
    "test_text = prepare_text('./Brown_Leseprobe_test.txt')\n",
    "test_set = TextDataset(test_text, args.seq_len, args.offset)\n",
    "test_loader = DataLoader(test_set, batch_size = args.batch_size, shuffle=True)\n",
    "\n",
    "# set further parameters\n",
    "char_idx = train_set.char_idx\n",
    "idx_char = train_set.idx_char\n",
    "no_classes = train_set.no_classes\n",
    "input_shape = (args.seq_len, no_classes) # seq_len * nr. of unique characters \n",
    "\n",
    "# get len of data to determine the possible batch_size\n",
    "print(args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 29)\n",
      "LSTM_RNN(\n",
      "  (lstm): LSTM(29, 128, num_layers=3)\n",
      "  (linear): Linear(in_features=128, out_features=29)\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "print(input_shape)\n",
    "rnn = LSTM_RNN(no_classes)\n",
    "if args.cuda:\n",
    "    rnn.cuda()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the optimization algorithm\n",
    "optimizer = optim.RMSprop(rnn.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "data:\n",
      "\n",
      "(0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   1  ...    0   0   0\n",
      "\n",
      "(1 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(2 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   1  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "...\n",
      "\n",
      "(78,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   1   0   0  ...    0   0   0\n",
      "\n",
      "(79,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   1   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(80,.,.) = \n",
      "   1   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   1   0   0  ...    0   0   0\n",
      "[torch.FloatTensor of size 81x30x29]\n",
      "\n",
      "target:\n",
      "\n",
      " 25\n",
      " 18\n",
      " 11\n",
      " 13\n",
      " 18\n",
      "  0\n",
      "  4\n",
      " 18\n",
      " 11\n",
      "  0\n",
      "  0\n",
      "  0\n",
      " 19\n",
      "  4\n",
      "  9\n",
      "  1\n",
      " 15\n",
      "  0\n",
      "  7\n",
      " 14\n",
      " 15\n",
      "  5\n",
      "  1\n",
      "  9\n",
      "  8\n",
      " 20\n",
      " 18\n",
      " 14\n",
      " 17\n",
      " 22\n",
      "  9\n",
      "  5\n",
      " 17\n",
      "  8\n",
      "  0\n",
      "  7\n",
      "  0\n",
      " 17\n",
      "  5\n",
      " 20\n",
      "  8\n",
      "  1\n",
      "  3\n",
      "  5\n",
      "  0\n",
      "  5\n",
      " 17\n",
      "  4\n",
      " 15\n",
      " 18\n",
      "  8\n",
      " 19\n",
      "  5\n",
      "  0\n",
      "  4\n",
      " 17\n",
      " 10\n",
      "  5\n",
      " 27\n",
      " 14\n",
      " 14\n",
      " 19\n",
      " 18\n",
      "  7\n",
      "  2\n",
      "  5\n",
      "  9\n",
      " 14\n",
      " 16\n",
      "  0\n",
      " 14\n",
      "  1\n",
      " 17\n",
      " 12\n",
      " 15\n",
      "  9\n",
      "  5\n",
      " 27\n",
      "  1\n",
      "  0\n",
      " 13\n",
      "[torch.DoubleTensor of size 81]\n",
      "\n",
      "output:\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  3.4161\n",
      "  3.4625\n",
      "  3.4309\n",
      "  3.4420\n",
      "  3.4496\n",
      "  3.4400\n",
      "  3.4807\n",
      "  3.4395\n",
      "  3.4418\n",
      "  3.4243\n",
      "  3.4651\n",
      "  3.4897\n",
      "  3.4735\n",
      "  3.4491\n",
      "  3.4071\n",
      "  3.4462\n",
      "  3.4830\n",
      "  3.4699\n",
      "  3.4520\n",
      "  3.4593\n",
      "  3.4429\n",
      "  3.4613\n",
      "  3.4530\n",
      "  3.4117\n",
      "  3.4650\n",
      "  3.4265\n",
      "  3.4487\n",
      "  3.4215\n",
      "  3.4472\n",
      "[torch.FloatTensor of size 29]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:79",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-d288d6b9bba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-253-586132c1e94c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# check how far away the output is from the original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 601\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \"\"\"\n\u001b[0;32m-> 1140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:79"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run training and store history\n",
    "history = dict()\n",
    "history['loss_train'] = []\n",
    "history['loss_test'] = []\n",
    "\n",
    "# wie wir die accuracy machen, weiß ich noch nicht...\n",
    "#history['acc_train'] = []\n",
    "#history['acc_test'] = []\n",
    "print(args.batch_size)\n",
    "for epoch in range(10):\n",
    "    loss_train = train(rnn, epoch)        \n",
    "    history['loss_train'].append(loss_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try a prediction\n",
    "\n",
    "#testdata = Variable(torch.from_numpy(test_set.data[0])) # get first element from the test set\n",
    "#truth = test_set.target[0]\n",
    "#print(testdata,truth)\n",
    "\n",
    "#prediction = rnn(testdata)\n",
    "## dann muss man hier noch auf die sizes achten, ach verdammt\n",
    "#prepare_input(\"This is an example of input for our LSTM\".lower(), train_set.data, char_idx)\n",
    "#print(predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test = \"hrend die historische Zahnrad \"\n",
    "predict_completion(rnn, test.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "{'ö': 26, 'c': 3, 'd': 4, 'j': 10, 'g': 7, 'p': 16, 'l': 12, 'e': 5, 'r': 17, 'b': 2, 't': 19, 'f': 6, 'ü': 27, ' ': 0, 'u': 20, 'z': 23, 'v': 21, 'k': 11, 'w': 22, 'ß': 24, 'o': 15, 'n': 14, 'ä': 25, 'i': 9, 'h': 8, 's': 18, '–': 28, 'm': 13, 'a': 1}\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print(train_set.no_classes)\n",
    "print(char_idx)\n",
    "print(args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
