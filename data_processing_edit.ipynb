{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- encoding: iso-8859-15 -*-\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Import other python files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration / parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_config(config_path = \"config.txt\", args = dict()):\n",
    "    with open(config_path) as source:\n",
    "        for line in source:\n",
    "            line = line.strip()\n",
    "            argLong, valueLong = line.split('=')\n",
    "            arg = argLong.strip()\n",
    "            value = valueLong.strip()\n",
    "            if value == 'True':\n",
    "                value = True\n",
    "            elif value == 'False':\n",
    "                value = False\n",
    "            elif '.' in value:\n",
    "                value = float(value)\n",
    "            else:\n",
    "                value = int(value)\n",
    "            args[arg] = value\n",
    "    return edict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq_len': 40, 'offset': 1, 'cuda': False, 'batch_size': 16, 'num_layers': 1, 'hidden_size': 128, 'lr': 0.1, 'clip': 1}\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "print(args)\n",
    "#args.batch_size = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(textsource):\n",
    "    text = ''\n",
    "    with open(textsource, encoding=\"utf8\") as txtsource:\n",
    "        for line in txtsource:\n",
    "            line = line.strip().lower()\n",
    "            line = line.replace(',', '').replace('.', '')\n",
    "            line = line.replace('»', '').replace('«', '')\n",
    "            line = line.replace('\"', '')\n",
    "            line = line.replace(u'\\ufeff', '')\n",
    "            text += ' ' + line\n",
    "    text = text[:32040] #### nachher wieder rauslöschen!!!\n",
    "    return text\n",
    "# Chevrons müssen noch weg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_len, offset):\n",
    "    # Get all the unique characters appearing in the text \n",
    "    chars = sorted(list(set(text)))\n",
    "    char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "    print('char_indices_map: ' + str(char_idx))\n",
    "    print('len(char_indices_map): ' + str(len(char_idx)))\n",
    "    idx_char = dict((i, c) for i, c in enumerate(chars)) #### das brauchen wir später!!!\n",
    "    no_classes = len(chars) # the nr. of unique characters corresponds to the nr. of classes\n",
    "    \n",
    "    # Define training samples by splitting the text\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - seq_len, offset):\n",
    "        sentences.append(text[i: i + seq_len])\n",
    "        next_chars.append(text[i + seq_len])\n",
    "\n",
    "    #print('sentences', sentences)    \n",
    "    #print('next_chars', next_chars)\n",
    "    print('nr training samples', len(sentences))\n",
    "    \n",
    "    # Generate features and labels using one-hot encoding\n",
    "    X = np.zeros((len(sentences), seq_len, len(chars)), dtype='f')\n",
    "    y = np.zeros((len(sentences)))\n",
    "    gt = np.zeros((len(sentences), len(chars)), dtype = 'f')\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for j, char in enumerate(sentence):\n",
    "            X[i, j, char_idx[char]] = 1\n",
    "        y[i] = char_idx[next_chars[i]]\n",
    "        gt[i, char_idx[next_chars[i]]] = 1\n",
    "        \n",
    "    #print('next_chars: ' + str(next_chars[0]))\n",
    "    #print('out: ' + str(X[0, :, :]))\n",
    "    #print('target: ' + str(y[0]))\n",
    "        \n",
    "    return X, y, gt, char_idx, idx_char, no_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    ''' A text dataset class which implements the abstract class torch.utils.data.Dataset. '''\n",
    "    def __init__(self, text, seq_len, offset):\n",
    "        self.data, self.target, self.gt, self.char_idx, self.idx_char, self.no_classes = prepare_data(text, seq_len, offset)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ''' Get the data for one training sample (by index) '''\n",
    "        return self.data[index,:,:], self.target[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' Get the number of training samples '''\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, no_classes):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = no_classes, hidden_size = args.hidden_size, num_layers = args.num_layers)\n",
    "        self.linear = nn.Linear(in_features = args.hidden_size, out_features = no_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        nn.init.normal( self.linear.weight, 0, 0.075)\n",
    "        nn.init.normal(self.linear.bias, 0, 0.075)\n",
    "        nn.init.xavier_normal(self.lstm.weight_hh_l0)\n",
    "        nn.init.xavier_normal(self.lstm.weight_ih_l0)\n",
    "        #nn.init.constant(self.lstm.bias, 0.0)\n",
    "\n",
    "        \n",
    "        # LSTM needs hidden variable which is initialized in self.init_hidden(self)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         m.weight.data.normal_(0, 0.075*0.075)\n",
    "        #         m.bias.data.normal_(0, 0.075*0.075)\n",
    "                \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        c0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        return (h0,c0)#Variable(torch.zeros((args.num_layers, args.batch_size, args.hidden_size)))\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        #x = x.type(torch.DoubleTensor)\n",
    "        #print(x)\n",
    "        lstm_out, hidden = self.lstm(x, hidden) # (h0, c0 are set to default values)\n",
    "        #print(lstm_out)\n",
    "        #print(\"LSTM_OUT:\")\n",
    "        #print(lstm_out)\n",
    "        #lstm_out = lstm_out.view(-1, lstm_out.size(2))\n",
    "        #print(\"----------------\")\n",
    "        #print(lstm_out)\n",
    "        linear_out = self.linear(lstm_out[-1])\n",
    "        #print(\"Linear_OUT:\")\n",
    "        #print(linear_out)\n",
    "        #res = self.softmax(linear_out) # use only the output of the last layer of lstm\n",
    "        return linear_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training loop (one epoch)\n",
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(data)\n",
    "        data = data.transpose(0, 1) #swap seq_len and batch:size\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"data:\")\n",
    "        #print(data[0, :, :])\n",
    "        output, hidden = model(data, hidden)\n",
    "        #print(\"output:\")\n",
    "        #print(output[0])\n",
    "        #print(\"target:\")\n",
    "        #print(target)\n",
    "        #print(\"output:\")\n",
    "        #print(output)\n",
    "        loss = criterion(output, target.type(torch.LongTensor)) # check how far away the output is from the original data\n",
    "        #print(\"loss:\")\n",
    "        #print(loss)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data[0]\n",
    "        #print(total_loss)\n",
    "\n",
    "\n",
    "    relative_loss = total_loss/float(len(train_loader))\n",
    "    print('Mean loss over epoch %s: %s' %(epoch, relative_loss))#loss.data[0]))\n",
    "    return relative_loss # return the relative loss for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation loop (one epoch)\n",
    "def evaluate(model, epoch):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(data)\n",
    "        data = data.transpose(0, 1)\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output, target.type(torch.LongTensor)) # check how far away the output is from the original data\n",
    "\n",
    "        total_loss += loss.data[0]\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    relative_loss = total_loss/float(len(train_loader))\n",
    "    print('Mean loss over epoch %s: %s' %(epoch, relative_loss))#loss.data[0]))\n",
    "    return relative_loss # return the relative loss for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction loop for ONE testdata tensor\n",
    "def rnn_predict(model, testdata):\n",
    "    ''' Note: testdata have to be submitted as a tensor'''\n",
    "    testdata = torch.from_numpy(testdata)\n",
    "    #print(\"testdata:\")\n",
    "    #print(testdata)\n",
    "    model.eval()\n",
    "    testdata = testdata.view(testdata.size(0), -1)\n",
    "    if args.cuda:\n",
    "        testdata = testdata.cuda()\n",
    "    testdata = testdata.type(torch.FloatTensor)\n",
    "    testdata = Variable(testdata)\n",
    "    hidden = model.init_hidden()\n",
    "    prediction = model(testdata, hidden)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Function that returns the largest factor of number that isn't the number itself '''\n",
    "def lfactor(num):\n",
    "    for i in range(num - 1, 0, -1): # go backwards from num - 1 to 1\n",
    "        if num % i == 0:            # if a number divides evenly\n",
    "            return i                # it's the largest factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marvins test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# die funktion brauchen wir vllt gar nicht, je nachdem ob wir den test loader verwenden oder wie wir das auch immer machen\n",
    "def prepare_input(text):\n",
    "    X = np.zeros((args.seq_len, no_classes))  # array with one entry which have 20 lines, each 11 entrys\n",
    "    offset = 0\n",
    "    if len(text)<args.seq_len:\n",
    "        offset = args.seq_len-len(text)\n",
    "    for t, char in enumerate(text):          \n",
    "        X[t+offset, char_idx[char]] = 1.\n",
    "    return X\n",
    "\n",
    "def sample(preds, top_n=1):\n",
    "    #print(\"test\")\n",
    "    preds = preds[-1].data.numpy()\n",
    "    #print(preds)\n",
    "    #print(preds.shape)\n",
    "    #preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(len(preds), zip(preds, itertools.count()))\n",
    "\n",
    "\n",
    "def predict_completion(model, text, topn=1):\n",
    "    original_text = text\n",
    "    processed = text\n",
    " \n",
    "    #print(len(processed))\n",
    "    max_iterations = 10\n",
    "    i = 0\n",
    "    completion = ''\n",
    "    next_char = '' # init\n",
    "    while next_char != ' ' and i < max_iterations:\n",
    "        i += 1\n",
    "        x = prepare_input(text)\n",
    "        preds = rnn_predict(model, x)\n",
    "        next_chars = sample(preds[0], top_n=topn)\n",
    "        #print('id, char: ' + str(next_chars[0][1]) + ', ' + str(idx_char[next_chars[0][1]]))\n",
    "        text = text[1:] + idx_char[next_chars[0][1]]\n",
    "        completion += idx_char[next_chars[0][1]]\n",
    "        next_char = idx_char[next_chars[0][1]]\n",
    "\n",
    "    return completion\n",
    "\n",
    "\n",
    "def predict_completions(model, text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.rnn_predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [idx_char[idx] + predict_completion(text[1:] + idx_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq_len': 40, 'offset': 1, 'cuda': False, 'batch_size': 16, 'num_layers': 1, 'hidden_size': 128, 'lr': 0.1, 'clip': 1}\nchar_indices_map: {' ': 0, '!': 1, '*': 2, '-': 3, '1': 4, '3': 5, '7': 6, '8': 7, '9': 8, ':': 9, ';': 10, '?': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37, 'ß': 38, 'ä': 39, 'ó': 40, 'ö': 41, 'ü': 42, 'ā': 43, '–': 44, '‘': 45, '’': 46, '…': 47, '‹': 48, '›': 49}\nlen(char_indices_map): 50\nnr training samples 32000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_indices_map: {' ': 0, '!': 1, '*': 2, '-': 3, '1': 4, '3': 5, '7': 6, '8': 7, '9': 8, ':': 9, ';': 10, '?': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37, 'ß': 38, 'ä': 39, 'ó': 40, 'ö': 41, 'ü': 42, 'ā': 43, '–': 44, '‘': 45, '’': 46, '…': 47, '‹': 48, '›': 49}\nlen(char_indices_map): 50\nnr training samples 32000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "print(args)\n",
    "\n",
    "# Generate train and test loader from our data\n",
    "train_text = prepare_text('./Brown_Leseprobe.txt')\n",
    "train_set = TextDataset(train_text, args.seq_len, args.offset)\n",
    "#args.batch_size = lfactor(len(train_set))\n",
    "train_loader = DataLoader(train_set, batch_size = args.batch_size, shuffle=False)\n",
    "gt = train_set.gt\n",
    "\n",
    "def dim(a):\n",
    "    if not type(a) == list:\n",
    "        return []\n",
    "    return [len(a)] + dim(a[0])\n",
    "\n",
    "# for i, val in enumerate(train_loader):\n",
    "#     print(val)\n",
    "#     if i==1:\n",
    "#         break\n",
    "\n",
    "test_text = prepare_text('./Brown_Leseprobe_test.txt')\n",
    "test_set = TextDataset(test_text, args.seq_len, args.offset)\n",
    "test_loader = DataLoader(test_set, batch_size = args.batch_size, shuffle=False)\n",
    "\n",
    "# set further parameters\n",
    "char_idx = train_set.char_idx\n",
    "idx_char = train_set.idx_char\n",
    "no_classes = train_set.no_classes\n",
    "input_shape = (args.seq_len, no_classes) # seq_len * nr. of unique characters \n",
    "\n",
    "# get len of data to determine the possible batch_size\n",
    "print(args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 50)\nLSTM_RNN(\n  (lstm): LSTM(50, 128)\n  (linear): Linear(in_features=128, out_features=50)\n  (softmax): Softmax()\n)\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "print(input_shape)\n",
    "rnn = LSTM_RNN(no_classes)\n",
    "if args.cuda:\n",
    "    rnn.cuda()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the optimization algorithm\n",
    "optimizer = optim.Adam(rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over epoch 0: 0.914361091222614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over epoch 0: 1.1703812665045261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over epoch 1: 0.8921527316980064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over epoch 1: 1.1976458085924386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over epoch 2: 0.8814950854219497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over epoch 2: 1.150560363523662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run training and store history\n",
    "#history = dict()\n",
    "#history['loss_train'] = []\n",
    "#history['loss_test'] = []\n",
    "\n",
    "# wie wir die accuracy machen, weiß ich noch nicht...\n",
    "#history['acc_train'] = []\n",
    "#history['acc_test'] = []\n",
    "print(args.batch_size)\n",
    "for epoch in range(10):\n",
    "    loss_train = train(rnn, epoch)\n",
    "    loss_test = evaluate(rnn, epoch)\n",
    "    history['loss_train'].append(loss_train)\n",
    "    history['loss_test'].append(loss_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\serialization.py:158: UserWarning: Couldn't retrieve source code for container of type LSTM_RNN. It won't be checked for correctness upon loading.\n  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6729128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(rnn, 'rnn_bsize16-l0.9.pt')\n",
    "\n",
    "def plotLineData(header, yLabel, firstData, firstLabel, firstColor='b', xLabel='epoch'):\n",
    "    plt.plot(firstData, color=firstColor)\n",
    "    plt.title(header)\n",
    "    plt.ylabel(yLabel)\n",
    "    plt.xlabel(xLabel)\n",
    "    plt.legend([firstLabel], loc='upper right')\n",
    "    plt.savefig(\"loss_test.png\")\n",
    "    plt.show()\n",
    "plotLineData(\"Loss\", \"loss\", history['loss_test'], \"loss\")\n",
    "# Try a prediction\n",
    "\n",
    "#testdata = Variable(torch.from_numpy(test_set.data[0])) # get first element from the test set\n",
    "#truth = test_set.target[0]\n",
    "#print(testdata,truth)\n",
    "\n",
    "#prediction = rnn(testdata)\n",
    "## dann muss man hier noch auf die sizes achten, ach verdammt\n",
    "#prepare_input(\"This is an example of input for our LSTM\".lower(), train_set.data, char_idx)\n",
    "#print(predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egung \nh \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uss \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "um \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ren \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eg \nr \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inflichen \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egenun \ne \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ten \n"
     ]
    }
   ],
   "source": [
    "\n",
    "testcases = [\"rfolge kleiner Eruptionen in heftige Bew\", \"während die historische zahnradbahn sic\", \n",
    "             \"hrend die historische zahnradbahn sich m\", \"nd die historische zahnradbahn sich mühs\", \n",
    "             \"e historische zahnradbahn sich mühsam ih\", \"torische zahnradbahn sich mühsam ihren w\", \n",
    "             \"che zahnradbahn sich mühsam ihren weg de\", \"hnradbahn sich mühsam ihren weg den schw\", \n",
    "             \"n sich mühsam ihren weg den schwindelerr\", \"am ihren weg den schwindelerregend steil\",\n",
    "             \"hwindelerregend steilen hang hinaufkrall\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ert \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ang \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gage \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ende \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itiert \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recht \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ustonische\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ichen \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saut \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chte \n"
     ]
    }
   ],
   "source": [
    "\n",
    "testcases = [\"mühsam ihren Weg den schwindel\", \"hen Außenhaut der reptilienart\", \n",
    "             \"schien das weitläufige Kloster\", \" flanke einer senkrecht aufrag\", \n",
    "             \"irsch auf die gezackten bergsp\", \"ebaut in die flanke einer senk\", \n",
    "             \"in den bergen und andere unbil\", \"hner vor der modernen welt abz\", \n",
    "             \"egend steilen Hang hinaufkrall\", \"uf magische Weise von der fels\",\n",
    "             \"den des Wetters und der Geschi\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chen \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kelt \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genden \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "er \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lligen \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ente \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukonne \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uschoften \n"
     ]
    }
   ],
   "source": [
    "testcases = [\"Während die historis\", \"ihren Weg den schwin\", \n",
    "             \"iner senkrecht aufra\", \"re Unbilden des Wett\", \n",
    "             \"eilen Hang hinaufkra\", \"die gezackten Bergsp\", \n",
    "             \"ichen Bestimmung abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chen \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ielt \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en \nf \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uschoften \n"
     ]
    }
   ],
   "source": [
    "testcases = [\"historis\", \"schw\", \"Garte\", \"senkrech\", \"Wett\",\n",
    "             \"hinau\", \"die gezackte\", \n",
    "             \"abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n{' ': 0, '!': 1, '*': 2, '-': 3, '1': 4, '3': 5, '7': 6, '8': 7, '9': 8, ':': 9, ';': 10, '?': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37, 'ß': 38, 'ä': 39, 'ó': 40, 'ö': 41, 'ü': 42, 'ā': 43, '–': 44, '‘': 45, '’': 46, '…': 47, '‹': 48, '›': 49}\n8\n"
     ]
    }
   ],
   "source": [
    "print(train_set.no_classes)\n",
    "print(char_idx)\n",
    "print(args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
