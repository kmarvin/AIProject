{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- encoding: iso-8859-15 -*-\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Import other python files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration / parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_config(config_path = \"config.txt\", args = dict()):\n",
    "    with open(config_path) as source:\n",
    "        for line in source:\n",
    "            line = line.strip()\n",
    "            argLong, valueLong = line.split('=')\n",
    "            arg = argLong.strip()\n",
    "            value = valueLong.strip()\n",
    "            if value == 'True':\n",
    "                value = True\n",
    "            elif value == 'False':\n",
    "                value = False\n",
    "            elif '.' in value:\n",
    "                value = float(value)\n",
    "            else:\n",
    "                value = int(value)\n",
    "            args[arg] = value\n",
    "    return edict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq_len': 5, 'offset': 1, 'cuda': False, 'batch_size': 32, 'num_layers': 1, 'hidden_size': 30, 'lr': 0.001, 'clip': 1}\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "print(args)\n",
    "#args.batch_size = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(textsource):\n",
    "    text = ''\n",
    "    with open(textsource, encoding=\"utf8\") as txtsource:\n",
    "        for line in txtsource:\n",
    "            line = line.strip().lower()\n",
    "            line = line.replace(',', '').replace('.', '')\n",
    "            line = line.replace('»', '').replace('«', '')\n",
    "            line = line.replace('\"', '')\n",
    "            line = line.replace(u'\\ufeff', '')\n",
    "            text += ' ' + line\n",
    "    text = text[:2408] #### nachher wieder rauslöschen!!!\n",
    "    return text\n",
    "# Chevrons müssen noch weg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_len, offset):\n",
    "    # Get all the unique characters appearing in the text \n",
    "    chars = sorted(list(set(text)))\n",
    "    char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "    print('char_indices_map: ' + str(char_idx))\n",
    "    print('len(char_indices_map): ' + str(len(char_idx)))\n",
    "    idx_char = dict((i, c) for i, c in enumerate(chars)) #### das brauchen wir später!!!\n",
    "    no_classes = len(chars) # the nr. of unique characters corresponds to the nr. of classes\n",
    "    \n",
    "    # count 'w' occurences, which is by far the least frequent with 1.6%\n",
    "    wcount = 0\n",
    "    for i in range(0, len(text) - seq_len, offset):\n",
    "        if text[i + seq_len] == 'w':\n",
    "            wcount += 1\n",
    "    \n",
    "    print('w-occurences: ' + str(wcount))\n",
    "            \n",
    "    # define counts and dict\n",
    "    counts_dict = {' ': 0, '-': 1, '?': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h':10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'z': 27, 'ß': 28, 'ä': 29, 'ö': 30, 'ü': 31, '–': 32, '…': 33, '‹': 34, '›': 35}\n",
    "    print('counts_dict: ' + str(counts_dict))\n",
    "    counts = [0]*len(counts_dict)\n",
    "    # Define training samples by splitting the text\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - seq_len, offset):\n",
    "        if text[i + seq_len] == ' ':\n",
    "            continue\n",
    "        else:#if counts[counts_dict[text[i + seq_len]]] <= wcount:\n",
    "            sentences.append(text[i: i + seq_len])\n",
    "            next_chars.append(text[i + seq_len])\n",
    "            #counts[counts_dict[text[i + seq_len]]] += 1\n",
    "\n",
    "    #print('sentences', sentences)    \n",
    "    #print('next_chars', next_chars)\n",
    "    print('nr training samples', len(sentences))\n",
    "    \n",
    "    # Generate features and labels using one-hot encoding\n",
    "    X = np.zeros((len(sentences), seq_len, len(chars)), dtype='f')\n",
    "    y = np.zeros((len(sentences)))\n",
    "    gt = np.zeros((len(sentences), len(chars)), dtype = 'f')\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for j, char in enumerate(sentence):\n",
    "            X[i, j, char_idx[char]] = 1\n",
    "        y[i] = char_idx[next_chars[i]]\n",
    "        gt[i, char_idx[next_chars[i]]] = 1\n",
    "        \n",
    "    #print('next_chars: ' + str(next_chars[0]))\n",
    "    #print('out: ' + str(X[0, :, :]))\n",
    "    #print('target: ' + str(y[0]))\n",
    "        \n",
    "    return X, y, gt, char_idx, idx_char, no_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    ''' A text dataset class which implements the abstract class torch.utils.data.Dataset. '''\n",
    "    def __init__(self, text, seq_len, offset):\n",
    "        self.data, self.target, self.gt, self.char_idx, self.idx_char, self.no_classes = prepare_data(text, seq_len, offset)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ''' Get the data for one training sample (by index) '''\n",
    "        return self.data[index,:,:], self.target[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' Get the number of training samples '''\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, no_classes):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = no_classes, hidden_size = args.hidden_size, num_layers = args.num_layers)\n",
    "        self.linear = nn.Linear(in_features = args.hidden_size, out_features = no_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        # self.linear.weight.data.normal_(0, 0.075**2)\n",
    "        # self.linear.bias.data.normal_(0, 0.075**2)\n",
    "        # for name, param in self.lstm.named_parameters():\n",
    "        #    if 'bias' in name:\n",
    "        #        nn.init.constant(param, 0.0)\n",
    "        #    elif 'weight' in name:\n",
    "        #        nn.init.xavier_normal(param) \n",
    "        #nn.init.xavier_uniform(self.lstm.weight_hh_l0)\n",
    "\n",
    "        \n",
    "        # LSTM needs hidden variable which is initialized in self.init_hidden(self)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         m.weight.data.normal_(0, 0.075*0.075)\n",
    "        #         m.bias.data.normal_(0, 0.075*0.075)\n",
    "                \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        c0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        return (h0,c0)#Variable(torch.zeros((args.num_layers, args.batch_size, args.hidden_size)))\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        #x = x.type(torch.DoubleTensor)\n",
    "        #print(x)\n",
    "        lstm_out, hidden = self.lstm(x, hidden) # (h0, c0 are set to default values)\n",
    "        #print(lstm_out)\n",
    "        #print(\"LSTM_OUT:\")\n",
    "        #print(lstm_out)\n",
    "        #lstm_out = lstm_out.view(-1, lstm_out.size(2))\n",
    "        #print(\"----------------\")\n",
    "        #print(lstm_out)\n",
    "        linear_out = self.linear(lstm_out[-1])\n",
    "        #print(\"Linear_OUT:\")\n",
    "        #print(linear_out)\n",
    "        #res = self.softmax(linear_out) # use only the output of the last layer of lstm\n",
    "        return linear_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training loop (one epoch)\n",
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(data)\n",
    "        data = data.view(data.size(1), data.size(0), data.size(2))\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"data:\")\n",
    "        #print(data[0])\n",
    "        output, hidden = model(data, hidden)\n",
    "        #print(\"output:\")\n",
    "        #print(output[0])\n",
    "        #print(\"target:\")\n",
    "        #print(target)\n",
    "        loss = criterion(output, target.type(torch.LongTensor)) # check how far away the output is from the original data\n",
    "        #print(\"loss:\")\n",
    "        #print(loss)\n",
    "        loss.backward()#retain_graph=True)\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data[0]\n",
    "        #print(total_loss)\n",
    "\n",
    "\n",
    "    relative_loss = total_loss/float(len(train_loader))\n",
    "    print('Relative loss over epoch %s: %s' %(epoch, relative_loss))#loss.data[0]))\n",
    "    return relative_loss # return the relative loss for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction loop for ONE testdata tensor\n",
    "def rnn_predict(model, testdata):\n",
    "    ''' Note: testdata have to be submitted as a tensor'''\n",
    "    testdata = torch.from_numpy(testdata)\n",
    "    print(\"testdata:\")\n",
    "    print(testdata)\n",
    "    model.eval()\n",
    "    testdata = testdata.view(testdata.size(0), -1)\n",
    "    if args.cuda:\n",
    "        testdata = testdata.cuda()\n",
    "    testdata = testdata.type(torch.FloatTensor)\n",
    "    testdata = Variable(testdata)\n",
    "    hidden = model.init_hidden()\n",
    "    prediction = model(testdata, hidden)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Function that returns the largest factor of number that isn't the number itself '''\n",
    "def lfactor(num):\n",
    "    for i in range(num - 1, 0, -1): # go backwards from num - 1 to 1\n",
    "        if num % i == 0:            # if a number divides evenly\n",
    "            return i                # it's the largest factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marvins test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# die funktion brauchen wir vllt gar nicht, je nachdem ob wir den test loader verwenden oder wie wir das auch immer machen\n",
    "def prepare_input(text):\n",
    "    X = np.zeros((args.seq_len, no_classes))  # array with one entry which have 20 lines, each 11 entrys\n",
    "    for t, char in enumerate(text):\n",
    "        X[t, char_idx[char]] = 1.\n",
    "    return X\n",
    "\n",
    "def sample(preds, top_n=1):\n",
    "    print(\"test\")\n",
    "    preds = preds[-1].data.numpy()\n",
    "    print(preds)\n",
    "    print(preds.shape)\n",
    "    #preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(len(preds), zip(preds, itertools.count()))\n",
    "\n",
    "\n",
    "def predict_completion(model, text, topn=1):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    next_char = ''\n",
    "    max_iterations = 1\n",
    "    i = 0\n",
    "    while next_char != ' ' and i < max_iterations:\n",
    "        i += 1\n",
    "        x = prepare_input(text)\n",
    "        preds = rnn_predict(model, x)\n",
    "        next_chars = sample(preds[0], top_n=topn)\n",
    "        print('id, char: ' + str(next_chars[0][1]) + ', ' + str(idx_char[next_chars[0][1]]))\n",
    "        text = text[1:] + idx_char[next_chars[0][1]]\n",
    "        completion += idx_char[next_chars[0][1]]\n",
    "\n",
    "    return completion\n",
    "\n",
    "\n",
    "def predict_completions(model, text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.rnn_predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [idx_char[idx] + predict_completion(text[1:] + idx_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq_len': 5, 'offset': 1, 'cuda': False, 'batch_size': 32, 'num_layers': 1, 'hidden_size': 30, 'lr': 0.001, 'clip': 1}\nchar_indices_map: {' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'z': 24, 'ß': 25, 'ä': 26, 'ö': 27, 'ü': 28, '–': 29}\nlen(char_indices_map): 30\nw-occurences: 33\ncounts_dict: {' ': 0, '-': 1, '?': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'z': 27, 'ß': 28, 'ä': 29, 'ö': 30, 'ü': 31, '–': 32, '…': 33, '‹': 34, '›': 35}\nnr training samples 2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_indices_map: {' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'z': 24, 'ß': 25, 'ä': 26, 'ö': 27, 'ü': 28, '–': 29}\nlen(char_indices_map): 30\nw-occurences: 33\ncounts_dict: {' ': 0, '-': 1, '?': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'z': 27, 'ß': 28, 'ä': 29, 'ö': 30, 'ü': 31, '–': 32, '…': 33, '‹': 34, '›': 35}\nnr training samples 2048\n32\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "print(args)\n",
    "\n",
    "# Generate train and test loader from our data\n",
    "train_text = prepare_text('./Brown_Leseprobe.txt')\n",
    "train_set = TextDataset(train_text, args.seq_len, args.offset)\n",
    "#args.batch_size = lfactor(len(train_set))\n",
    "train_loader = DataLoader(train_set, batch_size = args.batch_size, shuffle=False)\n",
    "gt = train_set.gt\n",
    "\n",
    "def dim(a):\n",
    "    if not type(a) == list:\n",
    "        return []\n",
    "    return [len(a)] + dim(a[0])\n",
    "\n",
    "# for i, val in enumerate(train_loader):\n",
    "#     print(val)\n",
    "#     if i==1:\n",
    "#         break\n",
    "\n",
    "test_text = prepare_text('./Brown_Leseprobe_test.txt')\n",
    "test_set = TextDataset(test_text, args.seq_len, args.offset)\n",
    "test_loader = DataLoader(test_set, batch_size = args.batch_size, shuffle=False)\n",
    "\n",
    "# set further parameters\n",
    "char_idx = train_set.char_idx\n",
    "idx_char = train_set.idx_char\n",
    "no_classes = train_set.no_classes\n",
    "input_shape = (args.seq_len, no_classes) # seq_len * nr. of unique characters \n",
    "\n",
    "# get len of data to determine the possible batch_size\n",
    "print(args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30)\nLSTM_RNN(\n  (lstm): LSTM(30, 30)\n  (linear): Linear(in_features=30, out_features=30)\n  (softmax): Softmax()\n)\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "print(input_shape)\n",
    "rnn = LSTM_RNN(no_classes)\n",
    "if args.cuda:\n",
    "    rnn.cuda()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the optimization algorithm\n",
    "optimizer = optim.Adadelta(rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (30) must match the size of tensor b (90) at non-singleton dimension 2",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-31197a6de7af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-300e27ecf505>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epoch)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#print(\"data:\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#print(data[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m#print(\"output:\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#print(output[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-bda3cdfa7346>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m#x = x.type(torch.DoubleTensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#print(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (h0, c0 are set to default values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m#print(lstm_out)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#print(\"LSTM_OUT:\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         )\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, weight, hidden)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mnexth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                 \u001b[0mhy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[1;31m# hack to handle LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[1;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mh_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mresetgate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_r\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0minputgate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_i\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mnewgate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_n\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresetgate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (30) must match the size of tensor b (90) at non-singleton dimension 2"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "# Run training and store history\n",
    "history = dict()\n",
    "history['loss_train'] = []\n",
    "history['loss_test'] = []\n",
    "\n",
    "# wie wir die accuracy machen, weiß ich noch nicht...\n",
    "#history['acc_train'] = []\n",
    "#history['acc_test'] = []\n",
    "print(args.batch_size)\n",
    "for epoch in range(100):\n",
    "    loss_train = train(rnn, epoch)        \n",
    "    history['loss_train'].append(loss_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try a prediction\n",
    "\n",
    "#testdata = Variable(torch.from_numpy(test_set.data[0])) # get first element from the test set\n",
    "#truth = test_set.target[0]\n",
    "#print(testdata,truth)\n",
    "\n",
    "#prediction = rnn(testdata)\n",
    "## dann muss man hier noch auf die sizes achten, ach verdammt\n",
    "#prepare_input(\"This is an example of input for our LSTM\".lower(), train_set.data, char_idx)\n",
    "#print(predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata:\n\n\nColumns 0 to 12 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     1     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     1     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 13 to 25 \n    0     0     0     0     0     0     0     0     0     0     0     1     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     1     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     1     0     0     0     0     0     0     0     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[-13.58520889  -0.73085392  -5.92194653 -14.96095562  -6.19572163\n  -7.12724972  -6.91755581  -7.49485302  -5.35822725  -4.80729008\n -14.61333847 -12.12929535  -5.76710129 -12.98401451 -10.20179081\n  -9.35855675 -15.86228466  -9.27043533  -7.74959755 -10.42033195\n  -8.1384306  -15.82632351  -7.4326458   -8.85763168  -9.76618958\n -11.66856956 -13.23912621 -13.45469856 -11.05496407 -17.00373459]\n(30,)\nid, char: 1, a\ntestdata:\n\n\nColumns 0 to 12 \n    1     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     1     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 13 to 25 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     1     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     1     0     0     0     0     0     0     0     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     0     0\n    1     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[-5.23971367 -9.78226948 -6.01142597 -0.25165558  1.78741384  3.51705933\n  0.58034277  2.90851021 -0.90520817  2.19002128 -3.0555315  -2.73260045\n -2.1540885  -2.36266398 -0.14662629 -7.36192703 -6.60469437  1.10278165\n -0.16317976 -0.66252267 -2.70747828 -6.41966057 -6.47487736 -2.78334093\n -0.23146582 -6.8606348  -6.18554306 -6.03698444 -2.52647209 -7.15844917]\n(30,)\nid, char: 5, e\ntestdata:\n\n\nColumns 0 to 12 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     1     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     1     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 13 to 25 \n    1     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     1     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     1     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[ -7.91667557  -3.74928904 -13.1648016   -6.3854332   -8.05573845\n  -3.44140267   2.21702504  -1.06547046  -5.72118998  -2.37489462\n -10.23575878   1.24320483  -5.86888885  -3.65601349  -6.37179327\n  -9.14662743 -16.46505928  -2.29305601   0.18096375  -1.84223282\n  -1.74599588 -11.55297375 -12.65033913  -7.20123148 -10.52479744\n  -6.56780624 -11.47157097  -0.07159901  -9.1425724   -4.24336147]\n(30,)\nid, char: 6, f\ntestdata:\n\n\nColumns 0 to 12 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     1     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     1     0     0     0     0     0     0     0     0\n    0     0     0     0     0     1     0     0     0     0     0     0     0\n\nColumns 13 to 25 \n    0     0     0     0     0     0     0     0     0     1     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     1     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[-14.13170242  -6.40852356  -2.78972077  -8.62195873  -4.39465618\n  -2.02446222 -19.83439636  -9.15957832  -5.93362188 -11.33668518\n -21.04007912 -11.36033916  -4.03604841 -13.96860313  -5.69864464\n  -9.8106575  -11.03947258  -8.28183174  -9.15033627  -8.10617447\n -10.73879242  -8.29781723  -8.55695343 -15.4024601   -7.49510717\n -18.06946182 -13.01795387 -21.42824173  -9.84256172 -16.84627914]\n(30,)\nid, char: 5, e\ntestdata:\n\n\nColumns 0 to 12 \n    0     0     0     0     0     1     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     1     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     1     0     0     0     0     0\n\nColumns 13 to 25 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     1     0     0     0     0     0     0     0     0\n    0     0     0     0     1     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[-12.01971054  -5.33706093 -14.7229929   -6.70680285  -1.7678473\n   1.29766059 -12.19607639  -9.62268734  -3.79091311  -5.49602938\n -14.09764099  -9.07126999  -5.25172853  -4.27965641  -3.81261349\n -12.01385307 -14.53599072   0.421471    -1.21972811  -3.14390874\n  -5.86274195 -12.6843996   -9.58738136 -10.63525391 -10.39788628\n -10.19372463 -12.97249985 -13.7136898   -6.54962015 -14.07065296]\n(30,)\nid, char: 5, e\ntestdata:\n\n\nColumns 0 to 12 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     1     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     1     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     1\n\nColumns 13 to 25 \n    0     0     0     0     0     1     0     0     0     0     0     0     0\n    0     0     0     0     0     0     1     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[ -7.60240459  -7.24415588 -11.84557056   0.24183846  -4.87985897\n  -0.28133392  -5.41038656  -3.33360815  -4.48121119  -0.77522635\n  -4.97302628  -6.48269653  -5.10525894  -0.73621255  -0.73507428\n  -9.62598801  -4.56940222   1.33916509   2.27484083  -2.31136918\n  -3.58432341  -9.02552414  -5.24451828  -7.71484852  -3.93636084\n  -9.5037241   -5.68795681  -7.21868324  -1.46254086  -8.29808807]\n(30,)\nid, char: 18, s\ntestdata:\n\n\nColumns 0 to 12 \n    0     0     0     0     0     0     0     0     0     0     0     1     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     1     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     1\n    0     0     0     0     0     0     0     0     0     0     0     0     1\n\nColumns 13 to 25 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     1     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[-12.73290825  -6.66370869 -16.55108833  -8.26384354  -7.57876015\n  -7.01994944 -13.52199078 -12.55748463  -9.03926468  -9.89918709\n -12.05023575 -20.53708839  -4.37266922 -13.34799957  -1.81522036\n  -2.38389516  -6.49858952  -4.41684341  -7.10036659  -0.69106269\n  -3.26040244 -10.46496296  -3.87823367 -11.51323128 -15.16980362\n  -6.10466576  -7.87158966 -14.6499691  -13.37369347 -14.65852165]\n(30,)\nid, char: 19, t\ntestdata:\n\n\nColumns 0 to 12 \n    0     1     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     1     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     1     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 13 to 25 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     1     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     1     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[-14.87147903  -7.17783165 -13.43349743 -12.43486881  -7.00252056\n  -8.11858749 -16.64503288 -12.46724129  -9.83315372 -11.63227749\n -19.33372879 -12.27107143  -6.18896151 -11.14031792  -7.60106134\n  -3.7469871  -15.71203709 -10.42520809 -10.32066441  -6.45733595\n  -5.98597002 -12.44264412 -12.57734966 -13.00585556 -13.42193985\n -11.96988297 -15.06747055 -15.58281708 -11.24665928 -15.01897717]\n(30,)\nid, char: 15, o\ntestdata:\n\n\nColumns 0 to 12 \n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     1     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n\nColumns 13 to 25 \n    0     0     0     0     0     1     0     0     0     0     0     0     0\n    0     0     0     1     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     0\n    0     0     0     0     0     0     1     0     0     0     0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     1     0\n\nColumns 26 to 29 \n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n    0     0     0     0\n[torch.DoubleTensor of size 5x30]\n\ntest\n[-14.32467461 -10.33098412 -14.26352692  -9.22569561  -4.55499458\n  -4.22193527 -15.66089153  -8.10635376 -11.01834965 -11.21178055\n -16.61751747 -15.08628368  -8.13858986  -9.35952759  -8.26626205\n  -4.35026503 -14.67196083  -4.99716902 -11.08646011  -4.92467308\n  -9.12251759  -9.69053364  -7.52034283 -14.38422775 -12.28134537\n -14.99819756  -9.50558281 -16.0212059  -12.44179535 -15.38553047]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n(30,)\nid, char: 5, e\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testcases = [\"zahnr\", \" währ\", \"mühsa\", \"winde\", \"erreg\", \"steil\", \"krall\", \"aufra\", \"spitz\"]\n",
    "for case in testcases:\n",
    "    predict_completion(rnn, case.lower(), topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "{'ö': 26, 'c': 3, 'd': 4, 'j': 10, 'g': 7, 'p': 16, 'l': 12, 'e': 5, 'r': 17, 'b': 2, 't': 19, 'f': 6, 'ü': 27, ' ': 0, 'u': 20, 'z': 23, 'v': 21, 'k': 11, 'w': 22, 'ß': 24, 'o': 15, 'n': 14, 'ä': 25, 'i': 9, 'h': 8, 's': 18, '–': 28, 'm': 13, 'a': 1}\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print(train_set.no_classes)\n",
    "print(char_idx)\n",
    "print(args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
