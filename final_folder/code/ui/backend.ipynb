{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask, redirect, url_for, request, render_template, send_from_directory, jsonify\n",
    "import torch\n",
    "from easydict import EasyDict as edict\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import heapq\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# In[2]:\n",
    "\n",
    "def set_config(config_path = \"../config.txt\", args = dict()):\n",
    "    ''' Function that reads configuration parameters from a text file source.\n",
    "    Returns an edict containing all parameters and their respective values. '''\n",
    "\n",
    "    with open(config_path) as source:\n",
    "        for line in source:\n",
    "            line = line.strip()\n",
    "            argLong, valueLong = line.split('=')\n",
    "            arg = argLong.strip()\n",
    "            value = valueLong.strip()\n",
    "            if value == 'True':\n",
    "                value = True\n",
    "            elif value == 'False':\n",
    "                value = False\n",
    "            elif '.' in value:\n",
    "                value = float(value)\n",
    "            else:\n",
    "                value = int(value)\n",
    "            args[arg] = value\n",
    "    return edict(args)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "config_path = '../config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "class LSTM_RNN(nn.Module):\n",
    "    ''' Class defining a recurrent neural network for text autocompletion tasks. '''\n",
    "\n",
    "    def __init__(self, no_classes):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "\n",
    "        self.lstm = nn.GRU(input_size = no_classes, hidden_size = args.hidden_size, num_layers = args.num_layers)\n",
    "        self.linear = nn.Linear(in_features = args.hidden_size, out_features = no_classes)\n",
    "        self.softmax = nn.Softplus()\n",
    "\n",
    "        nn.init.normal( self.linear.weight, 0, 0.075)\n",
    "        nn.init.normal(self.linear.bias, 0, 0.075)\n",
    "        nn.init.xavier_normal(self.lstm.weight_hh_l0)\n",
    "        nn.init.xavier_normal(self.lstm.weight_ih_l0)\n",
    "\n",
    "        # LSTM needs hidden variables which is initialized in self.init_hidden(self)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        c0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        return (h0)#,c0)#Variable(torch.zeros((args.num_layers, args.batch_size, args.hidden_size)))\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        lstm_out, hidden = self.lstm(x, hidden) # (h0, c0 are set to default values)\n",
    "        linear_out = self.linear(lstm_out[-1])\n",
    "        return linear_out, hidden\n",
    "\n",
    "def prepare_text(textsource):\n",
    "    ''' Function that reads a text from a textfile with encoding utf8.\n",
    "    It removes all special characters, but keeps spaces.\n",
    "    in:\n",
    "        textsource: path of the textfile to read\n",
    "    out:\n",
    "        text: string containing the text in lower case and without any special characters. '''\n",
    "\n",
    "    text = ''\n",
    "    with open(textsource, encoding=\"utf8\") as txtsource:\n",
    "        for line in txtsource:\n",
    "            line = line.strip().lower()\n",
    "            line = ''.join(c for c in line if c.isalnum() or c == ' ')\n",
    "            text += ' ' + line\n",
    "    text = text[:64100]\n",
    "    return text\n",
    "\n",
    "text = prepare_text('../nietzsche_eng_edit.txt')\n",
    "chars = sorted(list(set(text))) # get all the unique characters appearing in the text\n",
    "char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "idx_char = dict((i, c) for i, c in enumerate(chars))\n",
    "no_classes = len(chars) # the nr. of unique characters corresponds to the nr. of classes\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "def rnn_predict(model, testdata):\n",
    "    ''' Prediction loop for ONE testdata array '''\n",
    "\n",
    "    testdata = torch.from_numpy(testdata)\n",
    "    model.eval()\n",
    "\n",
    "    if args.cuda:\n",
    "        testdata = testdata.cuda()\n",
    "    \n",
    "    testdata = testdata.type(torch.FloatTensor)\n",
    "    testdata = Variable(testdata)\n",
    "    hidden = model.init_hidden()\n",
    "    prediction = model(testdata.unsqueeze(1), hidden)\n",
    "    \n",
    "    return prediction \n",
    "\n",
    "def prepare_input(text):\n",
    "    ''' Function to create an one-hot encoding for the given text '''\n",
    "\n",
    "    X = np.zeros((len(text), no_classes))\n",
    "    for t, char in enumerate(text):\n",
    "        X[t, char_idx[char]] = 1.\n",
    "    return X\n",
    "\n",
    "def sample(preds):\n",
    "    ''' Function returning the element(s) of preds with the highest probability. '''\n",
    "    preds = preds[-1].data.numpy()\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(len(preds), zip(preds, itertools.count()))\n",
    "\n",
    "def load_model():\n",
    "   return torch.load(\"../pred.pt\")\n",
    "\n",
    "def predict_completion(model, text, max_iterations=10, stop_on_space = True):\n",
    "    ''' Function that iteratively predicts the following character until a space is predicted '''\n",
    "    original_text = text\n",
    "    processed = text\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    completion = ''\n",
    "    next_char = ''\n",
    "    while next_char != ' ' and i < max_iterations:\n",
    "        i += 1\n",
    "        x = prepare_input(text)\n",
    "        preds = rnn_predict(model, x) # make a prediction\n",
    "        next_chars = sample(preds[0]) # find character with highest prob.\n",
    "        text = text[1:] + idx_char[next_chars[0][1]]\n",
    "        completion += idx_char[next_chars[0][1]]\n",
    "\n",
    "        if stop_on_space:\n",
    "            next_char = idx_char[next_chars[0][1]]\n",
    "            if next_char == ' ':\n",
    "                completion = completion[:-1]\n",
    "                break\n",
    "    return completion\n",
    "\n",
    "def save_word_in_dict(dictionary, word, prob):\n",
    "    if word in dictionary:\n",
    "        dictionary[word][\"number\"] += 1\n",
    "        dictionary[word][\"prob\"] += prob\n",
    "        if word[-1:] == ' ':\n",
    "            dictionary[word][\"finished\"] = True\n",
    "    else:\n",
    "        finished = False\n",
    "        if word == ' ':\n",
    "            finished = True\n",
    "        dictionary[word] = {\"number\": 1, \"finished\": finished, \"prob\": prob}\n",
    "    return dictionary\n",
    "    \n",
    "def find_next_chars(model, different_words, word, text, number_suggestions, min_treshold, max_iterations=10):\n",
    "    text += word\n",
    "    text = text[:100]\n",
    "    needed_number = different_words[word][\"number\"]\n",
    "    x = prepare_input(text)\n",
    "    preds = rnn_predict(model, x)\n",
    "    next_chars = sample(preds[0])\n",
    "    \n",
    "    words = []\n",
    "    probs = []\n",
    "    probs_sum = 0\n",
    "    different_words.pop(word, None) # delete key to add the new ones\n",
    "    count_words = 1\n",
    "    number_words = 0\n",
    "    i = 0\n",
    "    while number_words < needed_number and probs_sum < min_treshold and i < max_iterations:\n",
    "        new_word = word + idx_char[next_chars[i][1]]\n",
    "        words.append(new_word)\n",
    "        \n",
    "        probs_sum += next_chars[i][0]\n",
    "        prob_format = \"{0:.2f}\".format(next_chars[i][0])\n",
    "        probs.append(float(prob_format))\n",
    "        i += 1\n",
    "    \n",
    "    result = []\n",
    "    if(len(words) < needed_number):\n",
    "        diff = 1 - np.sum(probs)\n",
    "        probs[0] += diff\n",
    "        result = np.random.choice(words, needed_number, p=probs)\n",
    "    for word in result:\n",
    "        different_words = save_word_in_dict(different_words, word, 0)\n",
    "\n",
    "    return different_words\n",
    "            \n",
    "def predict_words(model, text, number_suggestions=1, min_treshold=0.90, max_iterations=20):\n",
    "    ''' Function to give a number of fitting words '''\n",
    "    text = text[:100]\n",
    "    original_text = text\n",
    "    different_words = {}\n",
    "    \n",
    "    # init words start letters\n",
    "    x = prepare_input(text)\n",
    "    preds = rnn_predict(model, x)\n",
    "    next_chars = sample(preds[0])\n",
    "    \n",
    "    i = 0\n",
    "    probs_sum = 0\n",
    "    words = []\n",
    "    probs = []\n",
    "    while len(different_words) < number_suggestions and probs_sum < min_treshold:\n",
    "        different_words = save_word_in_dict(different_words, idx_char[next_chars[i][1]], next_chars[i][0])\n",
    "        words.append(idx_char[next_chars[i][1]])\n",
    "        probs_sum += next_chars[i][0]\n",
    "        prob_format = \"{0:.2f}\".format(next_chars[i][0])\n",
    "        probs.append(float(prob_format))\n",
    "        i += 1\n",
    "    # status: words with one letter each, maybe to few\n",
    "    \n",
    "    result = []\n",
    "    if(len(words) < number_suggestions):\n",
    "        print(probs)\n",
    "        print(np.sum(probs))\n",
    "        diff = 1 - np.sum(probs)\n",
    "        probs[0] += diff\n",
    "        result = np.random.choice(words, number_suggestions-len(words), p=probs)\n",
    "    for word in result:\n",
    "        different_words = save_word_in_dict(different_words, word, different_words[word][\"prob\"])\n",
    "    print(different_words)\n",
    "    # status: words with one letter each, maybe some letters multiple\n",
    "    \n",
    "    iter = 0\n",
    "    while len(different_words) < number_suggestions and iter < max_iterations:\n",
    "        for word in list(different_words):\n",
    "            if different_words[word][\"number\"] > 1 and word != ' ':\n",
    "                print(word)\n",
    "                different_words = find_next_chars(model, different_words, word, original_text, number_suggestions, min_treshold)\n",
    "        iter += 1\n",
    "    # status: number_suggestions different word beginings in different_words\n",
    "    \n",
    "    # complete the not finished words\n",
    "    words = []\n",
    "    for word in different_words:\n",
    "        if different_words[word][\"finished\"] == False:\n",
    "            text = original_text + word\n",
    "            text = text[:100]\n",
    "            compl = predict_completion(model, text)\n",
    "            full_word = word + compl\n",
    "            words.append((different_words[word][\"prob\"], full_word))\n",
    "        else:\n",
    "            words.append((different_words[word][\"prob\"], word))\n",
    "    \n",
    "    # words with highest probability first \n",
    "    words.sort(key=lambda tup: tup[0], reverse=True)\n",
    "    format_words = list(map(lambda x: x[1], words))\n",
    "\n",
    "    return format_words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'settings': {'numberSuggestions': '3'}, 'text': 'and'}\n",
      "{'l': {'prob': 0.039700862, 'finished': False, 'number': 1}, ' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "[0.89, 0.04]\n",
      "0.93\n",
      "{'l': {'prob': 0.039700862, 'finished': False, 'number': 1}, ' ': {'prob': 1.7856319, 'finished': True, 'number': 2}}\n",
      "+++++++++++++\n",
      "{'l': {'prob': 0.039700862, 'finished': False, 'number': 1}, ' ': {'prob': 1.7856319, 'finished': True, 'number': 2}}\n",
      "last:\n",
      "{'l': {'prob': 0.039700862, 'finished': False, 'number': 1}, ' ': {'prob': 1.7856319, 'finished': True, 'number': 2}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Feb/2018 20:51:15] \"POST /computeInput HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'ly']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/normalize.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/main.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/app.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/bootstrap.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/modernizr-2.8.3.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/jquery-3.3.1.slim.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/angular.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/angular-route.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/app.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/view.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/bootstrap.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:24] \"GET /static/bootstrap.css.map HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:25] \"GET /static/view.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:25] \"GET /static/bootstrap.js.map HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:25] \"GET /static/settings.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:57:27] \"POST /computeInput HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'settings': {'numberSuggestions': 1}, 'text': 'and'}\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "+++++++++++++\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "last:\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "[' ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/normalize.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/main.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/app.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/bootstrap.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/modernizr-2.8.3.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/jquery-3.3.1.slim.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/angular.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/angular-route.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/app.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/view.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:03] \"GET /static/bootstrap.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:04] \"GET /static/bootstrap.css.map HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:04] \"GET /static/bootstrap.js.map HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:04] \"GET /static/view.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:04] \"GET /static/settings.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 20:59:08] \"POST /computeInput HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'settings': {'numberSuggestions': 1}, 'text': 'and'}\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "+++++++++++++\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "last:\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "[' ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Feb/2018 20:59:35] \"POST /computeInput HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'settings': {'numberSuggestions': 1}, 'text': 'and'}\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "+++++++++++++\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "last:\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "[' ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/normalize.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/main.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/app.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/bootstrap.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/modernizr-2.8.3.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/jquery-3.3.1.slim.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/angular.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/angular-route.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/app.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/view.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/bootstrap.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:53] \"GET /static/bootstrap.css.map HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:54] \"GET /static/bootstrap.js.map HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:54] \"GET /static/view.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:54] \"GET /static/settings.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2018 21:00:56] \"POST /computeInput HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'settings': {'numberSuggestions': 1}, 'text': 'and'}\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "+++++++++++++\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "last:\n",
      "{' ': {'prob': 0.89281595, 'finished': True, 'number': 1}}\n",
      "[' ']\n",
      "{'settings': {'numberSuggestions': 1}, 'text': 'and d'}\n",
      "{'o': {'prob': 0.40602785, 'finished': False, 'number': 1}}\n",
      "{'o': {'prob': 0.40602785, 'finished': False, 'number': 1}}\n",
      "+++++++++++++\n",
      "{'o': {'prob': 0.40602785, 'finished': False, 'number': 1}}\n",
      "last:\n",
      "{'o': {'prob': 0.40602785, 'finished': False, 'number': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Feb/2018 21:01:02] \"POST /computeInput HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o']\n",
      "{'settings': {'numberSuggestions': '2'}, 'text': 'and do d'}\n",
      "{'i': {'prob': 0.42966297, 'finished': False, 'number': 1}, 'e': {'prob': 0.31427994, 'finished': False, 'number': 1}}\n",
      "{'i': {'prob': 0.42966297, 'finished': False, 'number': 1}, 'e': {'prob': 0.31427994, 'finished': False, 'number': 1}}\n",
      "+++++++++++++\n",
      "{'i': {'prob': 0.42966297, 'finished': False, 'number': 1}, 'e': {'prob': 0.31427994, 'finished': False, 'number': 1}}\n",
      "last:\n",
      "{'i': {'prob': 0.42966297, 'finished': False, 'number': 1}, 'e': {'prob': 0.31427994, 'finished': False, 'number': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Feb/2018 21:01:10] \"POST /computeInput HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ist', 'e']\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__, template_folder='app', static_folder='app/static')\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/computeInput', methods=['POST'])\n",
    "def generate():\n",
    "    data = request.get_json()\n",
    "    if \"text\" in data and \"settings\" in data and data[\"text\"] != ' ':\n",
    "        numberSuggestions = data[\"settings\"][\"numberSuggestions\"]\n",
    "        numberSuggestions = int(float(numberSuggestions))\n",
    "        words = predict_words(model, data[\"text\"].lower(), numberSuggestions)\n",
    "        return jsonify(words)\n",
    "    else:\n",
    "        abort(500)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start = time.time()\n",
    "completion = predict_completion(model, test.lower())\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "print(completion)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
