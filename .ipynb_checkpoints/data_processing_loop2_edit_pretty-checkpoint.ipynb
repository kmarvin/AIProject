{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#-*- encoding: iso-8859-15 -*-\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import heapq\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration / parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_config(config_path = \"config.txt\", args = dict()):\n",
    "    ''' Function that reads configuration parameters from a text file source. \n",
    "    Returns an edict containing all parameters and their respective values. '''\n",
    "    \n",
    "    with open(config_path) as source:\n",
    "        for line in source:\n",
    "            line = line.strip()\n",
    "            argLong, valueLong = line.split('=')\n",
    "            arg = argLong.strip()\n",
    "            value = valueLong.strip()\n",
    "            if value == 'True':\n",
    "                value = True\n",
    "            elif value == 'False':\n",
    "                value = False\n",
    "            elif '.' in value:\n",
    "                value = float(value)\n",
    "            else:\n",
    "                value = int(value)\n",
    "            args[arg] = value\n",
    "    return edict(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(textsource):\n",
    "    ''' Function that reads a text from a textfile with encoding utf8. \n",
    "    It removes all special characters, but keeps spaces. \n",
    "    in: \n",
    "        textsource: path of the textfile to read\n",
    "    out:\n",
    "        text: string containing the text in lower case and without any special characters. '''\n",
    "    \n",
    "    text = ''\n",
    "    with open(textsource, encoding=\"utf8\") as txtsource:\n",
    "        for line in txtsource:\n",
    "            line = line.strip().lower()\n",
    "            line = ''.join(c for c in line if c.isalnum() or c == ' ')\n",
    "            text += ' ' + line\n",
    "    text = text[:64100]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_len, offset, char_idx, idx_char):\n",
    "    ''' Function that generates one-hot encoded training/test features and target vectors\n",
    "    from the given text.\n",
    "    in: \n",
    "        text: string containing the text from which the features should be generated from\n",
    "        seq_len: sequence length of one training/test sample\n",
    "        offset: offset by which two training/test samples should be spaced \n",
    "        char_idx: dictionary mapping unique chars to indices\n",
    "        idx_char: dictionary mapping indices to unique chars \n",
    "        \n",
    "    out:\n",
    "        X: One-hot encoded vector of features\n",
    "        y: vector of targets '''\n",
    "    \n",
    "    # Define training samples by splitting the text\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - seq_len, offset):\n",
    "        sentences.append(text[i: i + seq_len])\n",
    "        next_chars.append(text[i + seq_len])\n",
    "    \n",
    "    # Generate features and labels using one-hot encoding\n",
    "    X = np.zeros((len(sentences), seq_len, len(chars)), dtype='f')\n",
    "    y = np.zeros((len(sentences)))\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for j, char in enumerate(sentence):\n",
    "            X[i, j, char_idx[char]] = 1\n",
    "        y[i] = char_idx[next_chars[i]]\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    ''' A text dataset class which implements the abstract class torch.utils.data.Dataset. '''\n",
    "    \n",
    "    def __init__(self, text, seq_len, offset, char_idx, idx_char):\n",
    "        self.data, self.target = prepare_data(text, seq_len, offset, char_idx, idx_char)\n",
    "                                                                                                      \n",
    "    def __getitem__(self, index):\n",
    "        ''' Get the data for one training sample (by index) '''\n",
    "        return self.data[index,:,:], self.target[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' Get the number of training samples '''\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    ''' Class defining a recurrent neural network for text autocompletion tasks. '''\n",
    "    \n",
    "    def __init__(self, no_classes):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.GRU(input_size = no_classes, hidden_size = args.hidden_size, num_layers = args.num_layers)\n",
    "        self.linear = nn.Linear(in_features = args.hidden_size, out_features = no_classes)\n",
    "        self.softmax = nn.Softplus()\n",
    "        \n",
    "        nn.init.normal( self.linear.weight, 0, 0.075)\n",
    "        nn.init.normal(self.linear.bias, 0, 0.075)\n",
    "        nn.init.xavier_normal(self.lstm.weight_hh_l0)\n",
    "        nn.init.xavier_normal(self.lstm.weight_ih_l0)\n",
    "        \n",
    "        # LSTM needs hidden variables which is initialized in self.init_hidden(self)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        c0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        return (h0)#,c0)#Variable(torch.zeros((args.num_layers, args.batch_size, args.hidden_size)))\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        lstm_out, hidden = self.lstm(x, hidden) # (h0, c0 are set to default values)\n",
    "        linear_out = self.linear(lstm_out[-1])\n",
    "        return linear_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    ''' Training loop (one epoch) '''\n",
    "    \n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.transpose(0, 1) #swap seq_len and batch_size\n",
    "        \n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "    \n",
    "        # Iterate over a sequence, predict every next character and accumulate the loss \n",
    "        for c in range(args.seq_len - 1):\n",
    "            output, hidden = model(data[c, :, :].contiguous().view(1, -1, no_classes), hidden) \n",
    "            loss += criterion(output, decode(data[c+1, :, :])) # check how far away the output is from the original data\n",
    "            \n",
    "        output, hidden = model(data[args.seq_len-1, :, :].contiguous().view(1, -1, no_classes), hidden)\n",
    "        loss += criterion(output, target.type(torch.LongTensor))\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.data[0]\n",
    "\n",
    "    relative_loss = total_loss/float(len(train_loader)*args.seq_len)\n",
    "    print('Mean loss over epoch %s: %s' %(epoch, relative_loss))\n",
    "    return relative_loss # return the relative loss for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, epoch):\n",
    "    ''' Evaluation loop (one epoch)'''\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "        data = data.transpose(0, 1)\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output, target.type(torch.LongTensor)) \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get index of max log prob\n",
    "        correct += pred.eq(target.type(torch.LongTensor).data.view_as(pred)).cpu().sum() # check for true predictions\n",
    "\n",
    "        total_loss += loss.data[0]\n",
    "    \n",
    "    model.train()\n",
    "    relative_loss = total_loss/float(len(test_loader))\n",
    "    accuracy = correct/(len(test_loader)*args.batch_size)\n",
    "    print('Mean test loss over epoch %s: %s' %(epoch, relative_loss))#loss.data[0]))\n",
    "    print('Accuracy: ' + str(accuracy) + '([{}%])'.format(accuracy*100))\n",
    "    return relative_loss, accuracy # return the relative loss and accuracy for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_predict(model, testdata):\n",
    "    ''' Prediction loop for ONE testdata array '''\n",
    "\n",
    "    testdata = torch.from_numpy(testdata)\n",
    "    model.eval()\n",
    "\n",
    "    if args.cuda:\n",
    "        testdata = testdata.cuda()\n",
    "    \n",
    "    testdata = testdata.type(torch.FloatTensor)\n",
    "    testdata = Variable(testdata)\n",
    "    hidden = model.init_hidden()\n",
    "    prediction = model(testdata.unsqueeze(1), hidden)\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    ''' Function to create an one-hot encoding for the given text '''\n",
    "    \n",
    "    X = np.zeros((len(text), no_classes)) \n",
    "    for t, char in enumerate(text):          \n",
    "        X[t, char_idx[char]] = 1.\n",
    "    return X\n",
    "\n",
    "def sample(preds, top_n=1):\n",
    "    ''' Function returning the element(s) of preds with the highest probability. '''\n",
    "    preds = preds[-1].data.numpy()\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(len(preds), zip(preds, itertools.count()))\n",
    "\n",
    "\n",
    "def predict_completion(model, text, topn=1, max_iterations=10, stop_on_space = True):\n",
    "    ''' Function that iteratively predicts the following character until a space is predicted '''\n",
    "    original_text = text\n",
    "    processed = text\n",
    "\n",
    "    i = 0\n",
    "    completion = ''\n",
    "    next_char = '' \n",
    "    while next_char != ' ' and i < max_iterations:\n",
    "        \n",
    "        i += 1\n",
    "        x = prepare_input(text)\n",
    "        preds = rnn_predict(model, x) # make a prediction\n",
    "        next_chars = sample(preds[0], top_n=topn) # find character with highest prob.\n",
    "        text = text[1:] + idx_char[next_chars[0][1]]\n",
    "        completion += idx_char[next_chars[0][1]]\n",
    "        \n",
    "        if stop_on_space:\n",
    "            next_char = idx_char[next_chars[0][1]]\n",
    "            if next_char == ' ':\n",
    "                completion = completion[:-1]\n",
    "                break\n",
    "                \n",
    "    return completion\n",
    "\n",
    "def predict_completions(model, text, n=3):\n",
    "    ''' Function to give multiple possible completions of an input text. '''\n",
    "    x = prepare_input(text)\n",
    "    preds = model.rnn_predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [idx_char[idx] + predict_completion(text[1:] + idx_char[idx]) for idx in next_indices]\n",
    "\n",
    "\n",
    "def get_testcases(text, seq_lengths = (10,100), offset = 1):\n",
    "    ''' Function to generate test instances of different length from a given text. '''\n",
    "    validation_sentences = []\n",
    "    endings = []\n",
    "    for i in range(0, len(text) - seq_lengths[1], offset):\n",
    "        seq_len = random.randint(seq_lengths[0], seq_lengths[1])\n",
    "        validation_sentences.append(text[i: i + seq_len])\n",
    "        \n",
    "        ending = ''\n",
    "        while text[i + seq_len] != ' ':\n",
    "            ending += text[i + seq_len]\n",
    "            seq_len += 1\n",
    "        endings.append(ending)    \n",
    "    \n",
    "    idx = np.random.choice(np.arange(len(validation_sentences)), 50, replace=True)\n",
    "    testcases = [validation_sentences[i] for i in idx]\n",
    "    test_endings = [endings[i] for i in idx]\n",
    "    \n",
    "    return testcases, test_endings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findOnes(sample):\n",
    "    ''' Helper function to find the 1 in a one-hot encoded vector. '''\n",
    "    arr = sample.data.numpy()\n",
    "    i = 0\n",
    "    flag = False\n",
    "    for k in np.nditer(arr):\n",
    "        if k == 1:\n",
    "            flag = True\n",
    "            break\n",
    "        i += 1\n",
    "    if flag == True:\n",
    "        return i\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def decode(data):\n",
    "    ''' Function to find the index of one-hot encoded vector where the 1 is located. '''\n",
    "    class_tensor = torch.LongTensor(args.batch_size)\n",
    "    for i in range(args.batch_size):\n",
    "        class_tensor[i] = findOnes(data[i])\n",
    "    \n",
    "    return Variable(class_tensor)\n",
    "\n",
    "def lfactor(num):\n",
    "    ''' Function that returns the largest factor of number that isn't the number itself '''\n",
    "    \n",
    "    for i in range(num - 1, 0, -1): # go backwards from num - 1 to 1\n",
    "        if num % i == 0:            # if a number divides evenly\n",
    "            return i                # it's the largest factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotLineData(header, yLabel, firstData, firstLabel, firstColor='b', xLabel='epoch'):\n",
    "    ''' Plot function '''\n",
    "    \n",
    "    plt.plot(firstData, color=firstColor)\n",
    "    plt.title(header)\n",
    "    plt.ylabel(yLabel)\n",
    "    plt.xlabel(xLabel)\n",
    "    plt.legend([firstLabel], loc='upper right')\n",
    "    plt.savefig(\"loss_test_GRU_loop2_big_hs512_slow.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Use the whole text to generate char indices map and indices char map '''\n",
    "text = prepare_text('./nietzsche_eng_edit.txt')\n",
    "chars = sorted(list(set(text))) # get all the unique characters appearing in the text \n",
    "char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "idx_char = dict((i, c) for i, c in enumerate(chars)) \n",
    "no_classes = len(chars) # the nr. of unique characters corresponds to the nr. of classes\n",
    "\n",
    "''' Set further parameter input shape defined as seq_ * nr. of unique characters '''\n",
    "input_shape = (args.seq_len, no_classes) \n",
    "\n",
    "''' Generate train and test loader from our data '''\n",
    "train_text = prepare_text('./nietzsche_eng_train.txt')\n",
    "train_set = TextDataset(train_text, args.seq_len, args.offset, char_idx, idx_char)\n",
    "train_loader = DataLoader(train_set, batch_size = args.batch_size, shuffle=True)\n",
    "\n",
    "test_text = prepare_text('./nietzsche_eng_test.txt')\n",
    "test_set = TextDataset(test_text, args.seq_len, args.offset, char_idx, idx_char)\n",
    "test_loader = DataLoader(test_set, batch_size = args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 37)\n",
      "LSTM_RNN(\n",
      "  (lstm): GRU(37, 256, num_layers=2)\n",
      "  (linear): Linear(in_features=256, out_features=37)\n",
      "  (softmax): Softplus(beta=1, threshold=20)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Generate model or reload model (then outcomment the last line in this block)\n",
    "rnn = LSTM_RNN(no_classes)\n",
    "if args.cuda:\n",
    "    rnn.cuda()\n",
    "print(rnn)\n",
    "\n",
    "#rnn = torch.load(\"GRU_loop2_big_hs128-epoch#3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the optimization algorithm\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "Mean loss over epoch 0: 2.7850882360839844\n",
      "correct: 19650\n",
      "len loader: 125\n",
      "Mean test loss over epoch 0: 2.3821243476867675\n",
      "Accuracy: 0.30703125([30.703124999999996%])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython\\miniconda2\\lib\\site-packages\\torch\\serialization.py:158: UserWarning: Couldn't retrieve source code for container of type LSTM_RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Run training and store history\n",
    "history = dict()\n",
    "history['loss_train'] = []\n",
    "history['loss_test'] = []\n",
    "history['acc'] = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss_train = train(rnn, epoch)\n",
    "    loss_test, accuracy = evaluate(rnn, epoch)\n",
    "    history['loss_train'].append(loss_train)\n",
    "    history['loss_test'].append(loss_test)\n",
    "    history['acc'].append(accuracy)\n",
    "    torch.save(rnn, 'GRU_loop2_big_hs512_slow-epoch#{}.pt'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x62b7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create plots of train loss, test loss and accuracy\n",
    "plotLineData(\"Training loss\", \"loss\", history['loss_train'], \"loss\")\n",
    "plotLineData(\"Test loss\", \"loss\", history['loss_test'], \"loss\")\n",
    "plotLineData(\"Accuracy\", \"acc\", history['acc'], \"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testcases, test_endings = get_testcases(test_text, seq_lengths = (10,100), offset = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t everything that we call higher culture is based upon the spiritualising and intensifying ', 'intevremond who reproached him for ', ' is no doubt these coming ones will be least able to dispense with the serious and not unscr', 'amity might be involved ther', 'rmula of virtue ', 'onsider for ourselves  239 the weaker sex has in no previous age been treated w', 'ose modes of thinking which measure th', ' home old a dragon thence doth roam  noble titl', 't does what all nourishment does that does not merely conserveas the phy', 'ary courage the standingalone', 'ed north pole e', ' him only to suffer with his fellows  223 the hybrid europeana tolerably ugly plebeian taken all in ', 'dinganimal alone attains to honours and di', 'ise woman to defeminize herself in this manner and to imitate all the stupidities from which man in ', 'obliged to find', 's a violation an intentional injuring of the fundamental will of the spirit which instinctive', ' things in the old arrangementsin short growth or more properly the', ' of wisdom but rather as disagreeable fools and dangerous inte', 'ainful delight of tragedy is cruelty that which operates agreeably in socalled tragic sympath', 'hearts he would not easily find therein the inten', 'f disguises it enjoys also its feeling of security thereinit is preci', 'ncts there is stupidity in this movement an almos', 'ng were proved thereby in favour of woman as she is among men these ', 'what food means and she insists on being coo', ' of rank betwee', ' grandfathers in esteem and also at a little distance from us we europeans of the day after ', 'that is a typical sign of shallowmindedness and a thinker ', 'in our very uncertain and consequently very conciliatory cent', 'the will nothing is so adapted to the spirit of t', 'selves and what the spirit that leads us wants to be', ' contemning look the feeling of separation from the multitude with their duti', 'derstanding of its victimsa repeated pro', ' emancipation of woman insofar as it is desired and d', 'rather a condition of every highe', ' back in all directions we o', 'nswer for this diagnosis of the european diseasethe disease of the will is diffused unequally ove', 'upidities fr', 'paniard at the sight of the faggot and ', 'lfdenial in the religious sens', 'tes  226 we immoraliststhis world with which we are concerned in which we have ', 'o other religion is any longer preachedlet the psychologist have his ears open throu', 'ntancespasms to vivisection of conscience and to pascal', 'anifold enjoymen', 'imperious something which is ', 'reference of ignorance of arbitrary shut', 'd blue mocking twilight this aging civilization with ', 'so many generations must have prepared the way for the coming of the philosopher each of his ', 't its service an apparently opposed impulse of the spirit a sudde', 'ave the hard task and for our recreation gladly seek the company of beings under whose hand', ' the wagnerienne who with unhinged will undergoes the performance of tri'] ['of', 'his', 'upulous', 'ein', 'morality', 'ith', 'e', 'e', 'siologist', '', 'xpeditions', 'allabsolutely', 'spenses', 'europe', '', 'ly', '', 'rrogatorshave', 'y', 'tion', 'sely', 't', 'are', 'k', 'n', 'tomorrow', 'who', 'ury', 'he', '', 'es', 'of', 'emanded', 'r', 'urselves', 'r', 'om', 'stake', 'e', 'to', 'gh', 'like', 't', 'popularly', 'ting', 'its', 'virtues', 'nly', 's', 'stan']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predict_completion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6dc0d331a8b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestcases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcompletion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#print(test_endings[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict_completion' is not defined"
     ]
    }
   ],
   "source": [
    "# 17 hits - epoch 3 - hs512\n",
    "testcases, test_endings = ['t everything that we call higher culture is based upon the spiritualising and intensifying ', 'intevremond who reproached him for ', ' is no doubt these coming ones will be least able to dispense with the serious and not unscr', 'amity might be involved ther', 'rmula of virtue ', 'onsider for ourselves  239 the weaker sex has in no previous age been treated w', 'ose modes of thinking which measure th', ' home old a dragon thence doth roam  noble titl', 't does what all nourishment does that does not merely conserveas the phy', 'ary courage the standingalone', 'ed north pole e', ' him only to suffer with his fellows  223 the hybrid europeana tolerably ugly plebeian taken all in ', 'dinganimal alone attains to honours and di', 'ise woman to defeminize herself in this manner and to imitate all the stupidities from which man in ', 'obliged to find', 's a violation an intentional injuring of the fundamental will of the spirit which instinctive', ' things in the old arrangementsin short growth or more properly the', ' of wisdom but rather as disagreeable fools and dangerous inte', 'ainful delight of tragedy is cruelty that which operates agreeably in socalled tragic sympath', 'hearts he would not easily find therein the inten', 'f disguises it enjoys also its feeling of security thereinit is preci', 'ncts there is stupidity in this movement an almos', 'ng were proved thereby in favour of woman as she is among men these ', 'what food means and she insists on being coo', ' of rank betwee', ' grandfathers in esteem and also at a little distance from us we europeans of the day after ', 'that is a typical sign of shallowmindedness and a thinker ', 'in our very uncertain and consequently very conciliatory cent', 'the will nothing is so adapted to the spirit of t', 'selves and what the spirit that leads us wants to be', ' contemning look the feeling of separation from the multitude with their duti', 'derstanding of its victimsa repeated pro', ' emancipation of woman insofar as it is desired and d', 'rather a condition of every highe', ' back in all directions we o', 'nswer for this diagnosis of the european diseasethe disease of the will is diffused unequally ove', 'upidities fr', 'paniard at the sight of the faggot and ', 'lfdenial in the religious sens', 'tes  226 we immoraliststhis world with which we are concerned in which we have ', 'o other religion is any longer preachedlet the psychologist have his ears open throu', 'ntancespasms to vivisection of conscience and to pascal', 'anifold enjoymen', 'imperious something which is ', 'reference of ignorance of arbitrary shut', 'd blue mocking twilight this aging civilization with ', 'so many generations must have prepared the way for the coming of the philosopher each of his ', 't its service an apparently opposed impulse of the spirit a sudde', 'ave the hard task and for our recreation gladly seek the company of beings under whose hand', ' the wagnerienne who with unhinged will undergoes the performance of '\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  'tri'], ['of', 'his', 'upulous', 'ein', 'morality', 'ith', 'e', 'e', 'siologist', '', 'xpeditions', 'allabsolutely', 'spenses', 'europe', '', 'ly', '', 'rrogatorshave', 'y', 'tion', 'sely', 't', 'are', 'k', 'n', 'tomorrow', 'who', 'ury', 'he', '', 'es', 'of', 'emanded', 'r', 'urselves', 'r', 'om', 'stake', 'e', 'to', 'gh', 'like', 't', 'popularly', 'ting', 'its', 'virtues', 'nly', 's', 'stan']\n",
    "correct = 0\n",
    "for i, case in enumerate(testcases):\n",
    "    completion = predict_completion(rnn, case.lower())\n",
    "    print(completion)\n",
    "    if completion == test_endings[i]:\n",
    "        correct += 1\n",
    "        print(\"correct!\")\n",
    "        \n",
    "print('correct: {}'.format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t everything that we call higher culture is based upon the spiritualising and intensifying ', 'intevremond who reproached him for ', ' is no doubt these coming ones will be least able to dispense with the serious and not unscr', 'amity might be involved ther', 'rmula of virtue ', 'onsider for ourselves  239 the weaker sex has in no previous age been treated w', 'ose modes of thinking which measure th', ' home old a dragon thence doth roam  noble titl', 't does what all nourishment does that does not merely conserveas the phy', 'ary courage the standingalone', 'ed north pole e', ' him only to suffer with his fellows  223 the hybrid europeana tolerably ugly plebeian taken all in ', 'dinganimal alone attains to honours and di', 'ise woman to defeminize herself in this manner and to imitate all the stupidities from which man in ', 'obliged to find', 's a violation an intentional injuring of the fundamental will of the spirit which instinctive', ' things in the old arrangementsin short growth or more properly the', ' of wisdom but rather as disagreeable fools and dangerous inte', 'ainful delight of tragedy is cruelty that which operates agreeably in socalled tragic sympath', 'hearts he would not easily find therein the inten', 'f disguises it enjoys also its feeling of security thereinit is preci', 'ncts there is stupidity in this movement an almos', 'ng were proved thereby in favour of woman as she is among men these ', 'what food means and she insists on being coo', ' of rank betwee', ' grandfathers in esteem and also at a little distance from us we europeans of the day after ', 'that is a typical sign of shallowmindedness and a thinker ', 'in our very uncertain and consequently very conciliatory cent', 'the will nothing is so adapted to the spirit of t', 'selves and what the spirit that leads us wants to be', ' contemning look the feeling of separation from the multitude with their duti', 'derstanding of its victimsa repeated pro', ' emancipation of woman insofar as it is desired and d', 'rather a condition of every highe', ' back in all directions we o', 'nswer for this diagnosis of the european diseasethe disease of the will is diffused unequally ove', 'upidities fr', 'paniard at the sight of the faggot and ', 'lfdenial in the religious sens', 'tes  226 we immoraliststhis world with which we are concerned in which we have ', 'o other religion is any longer preachedlet the psychologist have his ears open throu', 'ntancespasms to vivisection of conscience and to pascal', 'anifold enjoymen', 'imperious something which is ', 'reference of ignorance of arbitrary shut', 'd blue mocking twilight this aging civilization with ', 'so many generations must have prepared the way for the coming of the philosopher each of his ', 't its service an apparently opposed impulse of the spirit a sudde', 'ave the hard task and for our recreation gladly seek the company of beings under whose hand', ' the wagnerienne who with unhinged will undergoes the performance of tri'] ['of', 'his', 'upulous', 'ein', 'morality', 'ith', 'e', 'e', 'siologist', '', 'xpeditions', 'allabsolutely', 'spenses', 'europe', '', 'ly', '', 'rrogatorshave', 'y', 'tion', 'sely', 't', 'are', 'k', 'n', 'tomorrow', 'who', 'ury', 'he', '', 'es', 'of', 'emanded', 'r', 'urselves', 'r', 'om', 'stake', 'e', 'to', 'gh', 'like', 't', 'popularly', 'ting', 'its', 'virtues', 'nly', 's', 'stan']\n",
      "but\n",
      "its\n",
      "eatess\n",
      "efore\n",
      "seem\n",
      "ith\n",
      "correct!\n",
      "at\n",
      "edgen\n",
      "siological\n",
      "ss\n",
      "ven\n",
      "the\n",
      "scourady\n",
      "the\n",
      "\n",
      "correct!\n",
      "ly\n",
      "correct!\n",
      "\n",
      "correct!\n",
      "rpretation\n",
      "y\n",
      "correct!\n",
      "tively\n",
      "sely\n",
      "correct!\n",
      "t\n",
      "correct!\n",
      "power\n",
      "ul\n",
      "n\n",
      "correct!\n",
      "and\n",
      "it\n",
      "ument\n",
      "he\n",
      "correct!\n",
      "\n",
      "correct!\n",
      "on\n",
      "blem\n",
      "omain\n",
      "r\n",
      "correct!\n",
      "ne\n",
      "r\n",
      "correct!\n",
      "om\n",
      "correct!\n",
      "about\n",
      "es\n",
      "a\n",
      "ght\n",
      "e\n",
      "t\n",
      "correct!\n",
      "to\n",
      "h\n",
      "a\n",
      "accemption\n",
      "nt\n",
      "\n",
      "en\n",
      "correct: 14\n"
     ]
    }
   ],
   "source": [
    "# 14 hits - epoch 9 - hs512\n",
    "\n",
    "correct = 0\n",
    "for i, case in enumerate(testcases):\n",
    "    completion = predict_completion(rnn, case.lower())\n",
    "    print(completion)\n",
    "    if completion == test_endings[i]:\n",
    "        correct += 1\n",
    "        print(\"correct!\")\n",
    "        \n",
    "print('correct: {}'.format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m in the superstitional or ideas of plato has been\n",
      " with the senses that the conception of the will t\n",
      " on the most serious as a principulations and as a\n",
      " and about the artifies of all the german taste at\n",
      " of the will to truth in the philosopher thing tha\n",
      " of which the conception of its own it has have be\n",
      " in the sense conscisestlactive it is a moral self\n",
      " of any with a colrate consequently of manner a pr\n",
      " conception of its own it has have been synted how\n",
      " comed it were the same time the superstition and \n",
      " as platonism the may reality doem and the most se\n"
     ]
    }
   ],
   "source": [
    "# bigset hs512 - epoch9\n",
    "testcases = [\"Paralysis\", \"spirituality\", \"justice\", \"expedition\", \"responsibility\",\n",
    "             \"freedom\", \"power\", \"virtues\", \"BELIEVE\",\n",
    "             \"psychologist\", \"intelligence\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower(), max_iterations=50, stop_on_space=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t everything that we call higher culture is based upon the spiritualising and intensifying ', 'intevremond who reproached him for ', ' is no doubt these coming ones will be least able to dispense with the serious and not unscr', 'amity might be involved ther', 'rmula of virtue ', 'onsider for ourselves  239 the weaker sex has in no previous age been treated w', 'ose modes of thinking which measure th', ' home old a dragon thence doth roam  noble titl', 't does what all nourishment does that does not merely conserveas the phy', 'ary courage the standingalone', 'ed north pole e', ' him only to suffer with his fellows  223 the hybrid europeana tolerably ugly plebeian taken all in ', 'dinganimal alone attains to honours and di', 'ise woman to defeminize herself in this manner and to imitate all the stupidities from which man in ', 'obliged to find', 's a violation an intentional injuring of the fundamental will of the spirit which instinctive', ' things in the old arrangementsin short growth or more properly the', ' of wisdom but rather as disagreeable fools and dangerous inte', 'ainful delight of tragedy is cruelty that which operates agreeably in socalled tragic sympath', 'hearts he would not easily find therein the inten', 'f disguises it enjoys also its feeling of security thereinit is preci', 'ncts there is stupidity in this movement an almos', 'ng were proved thereby in favour of woman as she is among men these ', 'what food means and she insists on being coo', ' of rank betwee', ' grandfathers in esteem and also at a little distance from us we europeans of the day after ', 'that is a typical sign of shallowmindedness and a thinker ', 'in our very uncertain and consequently very conciliatory cent', 'the will nothing is so adapted to the spirit of t', 'selves and what the spirit that leads us wants to be', ' contemning look the feeling of separation from the multitude with their duti', 'derstanding of its victimsa repeated pro', ' emancipation of woman insofar as it is desired and d', 'rather a condition of every highe', ' back in all directions we o', 'nswer for this diagnosis of the european diseasethe disease of the will is diffused unequally ove', 'upidities fr', 'paniard at the sight of the faggot and ', 'lfdenial in the religious sens', 'tes  226 we immoraliststhis world with which we are concerned in which we have ', 'o other religion is any longer preachedlet the psychologist have his ears open throu', 'ntancespasms to vivisection of conscience and to pascal', 'anifold enjoymen', 'imperious something which is ', 'reference of ignorance of arbitrary shut', 'd blue mocking twilight this aging civilization with ', 'so many generations must have prepared the way for the coming of the philosopher each of his ', 't its service an apparently opposed impulse of the spirit a sudde', 'ave the hard task and for our recreation gladly seek the company of beings under whose hand', ' the wagnerienne who with unhinged will undergoes the performance of tri'] ['of', 'his', 'upulous', 'ein', 'morality', 'ith', 'e', 'e', 'siologist', '', 'xpeditions', 'allabsolutely', 'spenses', 'europe', '', 'ly', '', 'rrogatorshave', 'y', 'tion', 'sely', 't', 'are', 'k', 'n', 'tomorrow', 'who', 'ury', 'he', '', 'es', 'of', 'emanded', 'r', 'urselves', 'r', 'om', 'stake', 'e', 'to', 'gh', 'like', 't', 'popularly', 'ting', 'its', 'virtues', 'nly', 's', 'stan']\n",
      "the\n",
      "the\n",
      "eates\n",
      "e\n",
      "and\n",
      "ith\n",
      "correct!\n",
      "e\n",
      "correct!\n",
      "ed\n",
      "siological\n",
      "\n",
      "correct!\n",
      "ven\n",
      "the\n",
      "strust\n",
      "the\n",
      "\n",
      "correct!\n",
      "\n",
      "\n",
      "correct!\n",
      "rpretation\n",
      "y\n",
      "correct!\n",
      "tion\n",
      "correct!\n",
      "sely\n",
      "correct!\n",
      "t\n",
      "correct!\n",
      "precestion\n",
      "ure\n",
      "n\n",
      "correct!\n",
      "the\n",
      "and\n",
      "istion\n",
      "he\n",
      "correct!\n",
      "\n",
      "correct!\n",
      "on\n",
      "founder\n",
      "eception\n",
      "r\n",
      "correct!\n",
      "ne\n",
      "r\n",
      "correct!\n",
      "om\n",
      "correct!\n",
      "the\n",
      "es\n",
      "a\n",
      "gh\n",
      "correct!\n",
      "uation\n",
      "t\n",
      "correct!\n",
      "the\n",
      "h\n",
      "the\n",
      "perhaps\n",
      "rs\n",
      "\n",
      "t\n",
      "correct: 17\n"
     ]
    }
   ],
   "source": [
    "# 17 hits - epoch 3 - hs128\n",
    "print(testcases, test_endings)\n",
    "correct = 0\n",
    "for i, case in enumerate(testcases):\n",
    "    completion = predict_completion(rnn, case.lower())\n",
    "    print(completion)\n",
    "    if completion == test_endings[i]:\n",
    "        correct += 1\n",
    "        print(\"correct!\")\n",
    "        \n",
    "print('correct: {}'.format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t everything that we call higher culture is based upon the spiritualising and intensifying ', 'intevremond who reproached him for ', ' is no doubt these coming ones will be least able to dispense with the serious and not unscr', 'amity might be involved ther', 'rmula of virtue ', 'onsider for ourselves  239 the weaker sex has in no previous age been treated w', 'ose modes of thinking which measure th', ' home old a dragon thence doth roam  noble titl', 't does what all nourishment does that does not merely conserveas the phy', 'ary courage the standingalone', 'ed north pole e', ' him only to suffer with his fellows  223 the hybrid europeana tolerably ugly plebeian taken all in ', 'dinganimal alone attains to honours and di', 'ise woman to defeminize herself in this manner and to imitate all the stupidities from which man in ', 'obliged to find', 's a violation an intentional injuring of the fundamental will of the spirit which instinctive', ' things in the old arrangementsin short growth or more properly the', ' of wisdom but rather as disagreeable fools and dangerous inte', 'ainful delight of tragedy is cruelty that which operates agreeably in socalled tragic sympath', 'hearts he would not easily find therein the inten', 'f disguises it enjoys also its feeling of security thereinit is preci', 'ncts there is stupidity in this movement an almos', 'ng were proved thereby in favour of woman as she is among men these ', 'what food means and she insists on being coo', ' of rank betwee', ' grandfathers in esteem and also at a little distance from us we europeans of the day after ', 'that is a typical sign of shallowmindedness and a thinker ', 'in our very uncertain and consequently very conciliatory cent', 'the will nothing is so adapted to the spirit of t', 'selves and what the spirit that leads us wants to be', ' contemning look the feeling of separation from the multitude with their duti', 'derstanding of its victimsa repeated pro', ' emancipation of woman insofar as it is desired and d', 'rather a condition of every highe', ' back in all directions we o', 'nswer for this diagnosis of the european diseasethe disease of the will is diffused unequally ove', 'upidities fr', 'paniard at the sight of the faggot and ', 'lfdenial in the religious sens', 'tes  226 we immoraliststhis world with which we are concerned in which we have ', 'o other religion is any longer preachedlet the psychologist have his ears open throu', 'ntancespasms to vivisection of conscience and to pascal', 'anifold enjoymen', 'imperious something which is ', 'reference of ignorance of arbitrary shut', 'd blue mocking twilight this aging civilization with ', 'so many generations must have prepared the way for the coming of the philosopher each of his ', 't its service an apparently opposed impulse of the spirit a sudde', 'ave the hard task and for our recreation gladly seek the company of beings under whose hand', ' the wagnerienne who with unhinged will undergoes the performance of tri'] ['of', 'his', 'upulous', 'ein', 'morality', 'ith', 'e', 'e', 'siologist', '', 'xpeditions', 'allabsolutely', 'spenses', 'europe', '', 'ly', '', 'rrogatorshave', 'y', 'tion', 'sely', 't', 'are', 'k', 'n', 'tomorrow', 'who', 'ury', 'he', '', 'es', 'of', 'emanded', 'r', 'urselves', 'r', 'om', 'stake', 'e', 'to', 'gh', 'like', 't', 'popularly', 'ting', 'its', 'virtues', 'nly', 's', 'stan']\n",
      "but\n",
      "its\n",
      "eatess\n",
      "efore\n",
      "seem\n",
      "ith\n",
      "correct!\n",
      "at\n",
      "edgen\n",
      "siological\n",
      "ss\n",
      "ven\n",
      "the\n",
      "scourady\n",
      "the\n",
      "\n",
      "correct!\n",
      "ly\n",
      "correct!\n",
      "\n",
      "correct!\n",
      "rpretation\n",
      "y\n",
      "correct!\n",
      "tively\n",
      "sely\n",
      "correct!\n",
      "t\n",
      "correct!\n",
      "power\n",
      "ul\n",
      "n\n",
      "correct!\n",
      "and\n",
      "it\n",
      "ument\n",
      "he\n",
      "correct!\n",
      "\n",
      "correct!\n",
      "on\n",
      "blem\n",
      "omain\n",
      "r\n",
      "correct!\n",
      "ne\n",
      "r\n",
      "correct!\n",
      "om\n",
      "correct!\n",
      "about\n",
      "es\n",
      "a\n",
      "ght\n",
      "e\n",
      "t\n",
      "correct!\n",
      "to\n",
      "h\n",
      "a\n",
      "accemption\n",
      "nt\n",
      "\n",
      "en\n",
      "correct: 14\n"
     ]
    }
   ],
   "source": [
    "# 14 hits - epoch 9 - hs128\n",
    "print(testcases, test_endings)\n",
    "correct = 0\n",
    "for i, case in enumerate(testcases):\n",
    "    completion = predict_completion(rnn, case.lower())\n",
    "    print(completion)\n",
    "    if completion == test_endings[i]:\n",
    "        correct += 1\n",
    "        print(\"correct!\")\n",
    "        \n",
    "print('correct: {}'.format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m in the superstitional or ideas of plato has been\n",
      " with the senses that the conception of the will t\n",
      " on the most serious as a principulations and as a\n",
      " and about the artifies of all the german taste at\n",
      " of the will to truth in the philosopher thing tha\n",
      " of which the conception of its own it has have be\n",
      " in the sense conscisestlactive it is a moral self\n",
      " of any with a colrate consequently of manner a pr\n",
      " conception of its own it has have been synted how\n",
      " comed it were the same time the superstition and \n",
      " as platonism the may reality doem and the most se\n"
     ]
    }
   ],
   "source": [
    "# bigset hs128 - epoch9\n",
    "testcases = [\"Paralysis\", \"spirituality\", \"justice\", \"expedition\", \"responsibility\",\n",
    "             \"freedom\", \"power\", \"virtues\", \"BELIEVE\",\n",
    "             \"psychologist\", \"intelligence\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower(), max_iterations=50, stop_on_space=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anden \n",
      "h \n",
      "an \n",
      "ten \n",
      "m \n",
      "erde \n",
      "r \n",
      "ische \n",
      "en \n",
      "en \n",
      "te \n"
     ]
    }
   ],
   "source": [
    "# 40 chars\n",
    "testcases = [\"rfolge kleiner Eruptionen in heftige Bew\", \"whrend die historische zahnradbahn sic\", \n",
    "             \"hrend die historische zahnradbahn sich m\", \"nd die historische zahnradbahn sich mhs\", \n",
    "             \"e historische zahnradbahn sich mhsam ih\", \"torische zahnradbahn sich mhsam ihren w\", \n",
    "             \"che zahnradbahn sich mhsam ihren weg de\", \"hnradbahn sich mhsam ihren weg den schw\", \n",
    "             \"n sich mhsam ihren weg den schwindelerr\", \"am ihren weg den schwindelerregend steil\",\n",
    "             \"hwindelerregend steilen hang hinaufkrall\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-e6cb98629866>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m              \"den des Wetters und der Geschi\"]\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestcases\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-bf4620dcfb3f>\u001b[0m in \u001b[0;36mpredict_completion\u001b[1;34m(model, text, topn, max_iterations, stop_on_space)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mnext_char\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mnext_chars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-bf4620dcfb3f>\u001b[0m in \u001b[0;36mprepare_input\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# array with one entry which have 20 lines, each 11 entrys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "# 30 chars\n",
    "testcases = [\"mhsam ihren Weg den schwindel\", \"hen Auenhaut der reptilienart\", \n",
    "             \"chien das weitlufige Klosterg\", \" flanke einer senkrecht aufrag\", \n",
    "             \"irsch auf die gezackten bergsp\", \"ebaut in die flanke einer senk\", \n",
    "             \"in den bergen und andere unbil\", \"hner vor der modernen welt abz\", \n",
    "             \"egend steilen Hang hinaufkrall\", \"uf magische Weise von der fels\",\n",
    "             \"den des Wetters und der Geschi\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che \n",
      "der \n",
      "ng \n",
      "ers \n",
      "uben \n",
      "itlen \n",
      "uschoften \n",
      "uschoften \n"
     ]
    }
   ],
   "source": [
    "# 20 chars\n",
    "testcases = [\"Whrend die historis\", \"ihren Weg den schwin\", \n",
    "             \"iner senkrecht aufra\", \"re Unbilden des Wett\", \n",
    "             \"eilen Hang hinaufkra\", \"die gezackten Bergsp\", \n",
    "             \"ichen Bestimmung abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cher \n",
      "eider \n",
      "n \n",
      "t \n",
      "er \n",
      "f \n",
      "n \n",
      "ukormatige\n",
      "uschotten \n"
     ]
    }
   ],
   "source": [
    "# words\n",
    "testcases = [\"historis\", \"schw\", \"Garte\", \"senkrech\", \"Wett\",\n",
    "             \"hinau\", \"die gezackte\", \n",
    "             \"abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cher konneren werden  der bischof stie der einfh\n",
      "den dass sie sich den blickte kirsch eine auf das \n",
      "en auf dem bischof valdespino ihr bewasst die auf \n",
      "t aufgesommen dass sie schweiden alte liebens der \n",
      " aus den blickte kirsch eine auf das gelchert hab\n",
      "uf ans zu seinen weiter aus aus aus aus aus aus au\n",
      "n sie sich dann sich der eingeschchtert als er di\n",
      "lich dar  eine gemaue gebeten  aus praar auf dem b\n",
      "en in den blickte kirsch eine auf das gelchert ha\n",
      "n dass sie schweiden aller welt er seine beiden kl\n",
      "uschotten das werte die schwellen  der bischof in \n"
     ]
    }
   ],
   "source": [
    "# hs512\n",
    "# generate text\n",
    "testcases = [\"historis\", \"schwer\", \"Prophet\", \"senkrech\", \"Wetter\",\n",
    "             \"hina\", \"die gezackte\", \"ursprng\", \"kolleg\",\n",
    "             \"abzukomme\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower(), max_iterations=50, stop_on_space=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che mopf die gesagte der bischof anter auf der bes\n",
      "sch eine mochte kirsch eine mochte kirsch eine moc\n",
      "e ich der besteren des wissen die sie seine mochte\n",
      "en welte die ein seinen besuchsten mellte die ein \n",
      " ihr habe die gesagte die gesagte die gesagte die \n",
      "lle frde er der bergesch einer gewarden besihm li\n",
      " die gesagte ihn haben wie die gesagte ihn haben w\n",
      "licht weise er den besten der bischof anter auf de\n",
      "en in der bester der bester der bester der bester \n",
      "n sie hatten wie sie haben der bischof sich den be\n",
      "u kirsch ein seine meinen weiter auf der klang ein\n"
     ]
    }
   ],
   "source": [
    "# hs64\n",
    "testcases = [\"historis\", \"schwer\", \"Prophet\", \"senkrech\", \"Wetter\",\n",
    "             \"hina\", \"die gezackte\", \"ursprng\", \"kolleg\",\n",
    "             \"abzukomme\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower(), max_iterations=50, stop_on_space=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eiter \n"
     ]
    }
   ],
   "source": [
    "testcases = [\"Uhrw\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
