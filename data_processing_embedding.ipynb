{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-*- encoding: iso-8859-15 -*-\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "\n",
    "# Import other python files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration / parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_config(config_path = \"config.txt\", args = dict()):\n",
    "    with open(config_path) as source:\n",
    "        for line in source:\n",
    "            line = line.strip()\n",
    "            argLong, valueLong = line.split('=')\n",
    "            arg = argLong.strip()\n",
    "            value = valueLong.strip()\n",
    "            if value == 'True':\n",
    "                value = True\n",
    "            elif value == 'False':\n",
    "                value = False\n",
    "            elif '.' in value:\n",
    "                value = float(value)\n",
    "            else:\n",
    "                value = int(value)\n",
    "            args[arg] = value\n",
    "    return edict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 3, 'clip': 50, 'hidden_size': 128, 'seq_len': 30, 'offset': 4, 'lr': 0.001, 'cuda': False, 'batch_size': 81}\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "print(args)\n",
    "#args.batch_size = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(textsource):\n",
    "    text = ''\n",
    "    with open(textsource, encoding=\"utf8\") as txtsource:\n",
    "        for line in txtsource:\n",
    "            line = line.strip().lower()\n",
    "            line = line.replace(',', '').replace('.', '')\n",
    "            line = line.replace('»', '').replace('«', '')\n",
    "            line = line.replace('\"', '')\n",
    "            line = line.replace(u'\\ufeff', '')\n",
    "            text += ' ' + line\n",
    "    text = text[:1000] #### nachher wieder rauslöschen!!!\n",
    "    return text\n",
    "# Chevrons müssen noch weg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_len, offset):\n",
    "    # Get all the unique characters appearing in the text \n",
    "    chars = sorted(list(set(text)))\n",
    "    char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "    #print(char_idx)\n",
    "    #print(len(char_idx))\n",
    "    idx_char = dict((i, c) for i, c in enumerate(chars)) #### das brauchen wir später!!!\n",
    "    no_classes = len(chars) # the nr. of unique characters corresponds to the nr. of classes\n",
    "    \n",
    "    # Define training samples by splitting the text\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - seq_len, offset):\n",
    "        sentences.append(text[i: i + seq_len])\n",
    "        next_chars.append(text[i + seq_len])\n",
    "    print('nr training samples', len(sentences))\n",
    "    print(sentences[1])\n",
    "    print(next_chars[1])\n",
    "    # Generate features and labels using one-hot encoding\n",
    "    #X = np.zeros((len(sentences), seq_len, len(chars)), dtype='f')\n",
    "    #y = np.zeros((len(sentences)))\n",
    "    \n",
    "    #for i, sentence in enumerate(sentences):\n",
    "    #    for j, char in enumerate(sentence):\n",
    "    #        X[i, j, char_idx[char]] = 1\n",
    "    #    y[i] = char_idx[next_chars[i]]\n",
    "        \n",
    "    x = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        x.append(list(sentence))\n",
    "    np.asarray(x)\n",
    "    return x, next_chars, char_idx, idx_char, no_classes\n",
    "    #return X, y, char_idx, idx_char, no_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    ''' A text dataset class which implements the abstract class torch.utils.data.Dataset. '''\n",
    "    def __init__(self, text, seq_len, offset):\n",
    "        self.data, self.target, self.char_idx, self.idx_char, self.no_classes = prepare_data(text, seq_len, offset)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ''' Get the data for one training sample (by index) '''\n",
    "        return self.data[index], self.target[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' Get the number of training samples '''\n",
    "        return len(self.data)\n",
    "        #return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, no_classes):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Embedding(args.batch_size, no_classes)\n",
    "        self.lstm = nn.LSTM(input_size = no_classes, hidden_size = args.hidden_size, num_layers = 2)\n",
    "        self.linear = nn.Linear(in_features = args.hidden_size, out_features = no_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        #self.linear.weight.data.normal_(0, 0.075**2)\n",
    "        #self.linear.bias.data.normal_(0, 0.075**2)\n",
    "        #for name, param in self.lstm.named_parameters():\n",
    "        #    if 'bias' in name:\n",
    "        #        nn.init.constant(param, 0.0)\n",
    "        #    elif 'weight' in name:\n",
    "        #        nn.init.xavier_normal(param) \n",
    "        #nn.init.xavier_uniform(self.lstm.weight_hh_l0)\n",
    "\n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         m.weight.data.normal_(0, 0.075*0.075)\n",
    "        #         m.bias.data.normal_(0, 0.075*0.075)\n",
    "        self.hidden = self.init_hidden()      \n",
    "    \n",
    "    def init_hidden(self, batch_size=args.batch_size):\n",
    "        h0 = Variable(torch.zeros(args.num_layers, batch_size, args.hidden_size))\n",
    "        c0 = Variable(torch.zeros(args.num_layers, batch_size, args.hidden_size))\n",
    "        self.hidden = (h0, c0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"x:\")\n",
    "        print(x)\n",
    "        embedding_out = self.encoder(x)\n",
    "        print(\"embedding_out:\")\n",
    "        print(embedding_out)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden) # (h0, c0 are set to default values)\n",
    "        #print(lstm_out)\n",
    "        #print(\"LSTM_OUT:\")\n",
    "        #print(lstm_out)\n",
    "        #lstm_out = lstm_out.view(-1, lstm_out.size(2))\n",
    "        #print(\"----------------\")\n",
    "        #print(lstm_out)\n",
    "        linear_out = self.linear(lstm_out[-1])\n",
    "        #print(\"Linear_OUT:\")\n",
    "        #print(linear_out)\n",
    "        \n",
    "        return linear_out\n",
    "        #res = self.softmax(linear_out) # use only the output of the last layer of lstm\n",
    "        #return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training loop (one epoch)\n",
    "def train(model, epoch):\n",
    "    hiddenLayers = model.init_hidden()\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "    print(enumerate(train_loader))\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(\"data:\")\n",
    "        #print(data)\n",
    "        #print(\"target:\")\n",
    "        #print(target)\n",
    "        data = data.view(data.size(1), data.size(0), data.size(2))\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"data:\")\n",
    "        #print(data[0])\n",
    "        output = model(data)\n",
    "        #print(\"output:\")\n",
    "        #print(output[0])\n",
    "        #print(\"target:\")\n",
    "        #print(target)\n",
    "        loss = criterion(output, target.type(torch.LongTensor)) # check how far away the output is from the original data\n",
    "        #print(\"loss:\")\n",
    "        #print(loss)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data[0]\n",
    "        #print(total_loss)\n",
    "\n",
    "\n",
    "    relative_loss = total_loss/float(len(train_loader))\n",
    "    print('Relative loss over epoch %s: %s' %(epoch, relative_loss))\n",
    "    return relative_loss # return the relative loss for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction loop for ONE testdata tensor\n",
    "def rnn_predict(model, testdata):\n",
    "    ''' Note: testdata have to be submitted as a tensor'''\n",
    "    testdata = torch.from_numpy(testdata)\n",
    "    #print(\"testdata:\")\n",
    "    #print(testdata)\n",
    "    model.eval()\n",
    "    #testdata = testdata.view(testdata.size(0), -1)\n",
    "    if args.cuda:\n",
    "        testdata = testdata.cuda()\n",
    "    testdata = testdata.type(torch.FloatTensor)\n",
    "    testdata = Variable(testdata)\n",
    "    prediction = model(testdata)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Function that returns the largest factor of number that isn't the number itself '''\n",
    "def lfactor(num):\n",
    "    for i in range(num - 1, 0, -1): # go backwards from num - 1 to 1\n",
    "        if num % i == 0:            # if a number divides evenly\n",
    "            return i                # it's the largest factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marvins test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# die funktion brauchen wir vllt gar nicht, je nachdem ob wir den test loader verwenden oder wie wir das auch immer machen\n",
    "def prepare_input(text):\n",
    "    X = np.zeros((1, args.seq_len, no_classes))  # array with one entry which have 20 lines, each 11 entrys\n",
    "    for t, char in enumerate(text):\n",
    "        X[0, t, char_idx[char]] = 1.\n",
    "    return X\n",
    "\n",
    "def sample(preds, top_n=1):\n",
    "    preds = preds.data.numpy()[0]\n",
    "    print(preds)\n",
    "    print(preds.shape)\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
    "\n",
    "\n",
    "def predict_completion(model, text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    next_char = ''\n",
    "    max_iterations = 30\n",
    "    i = 0\n",
    "    while next_char != ' ' and i < max_iterations:\n",
    "        i += 1\n",
    "        x = prepare_input(text)\n",
    "        #print(\"x:\")\n",
    "        #print(x)\n",
    "        preds = rnn_predict(model, x)\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = idx_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "\n",
    "    return completion\n",
    "\n",
    "\n",
    "def predict_completions(model, text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.rnn_predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [idx_char[idx] + predict_completion(text[1:] + idx_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr training samples 243\n",
      "rend die historische zahnradba\n",
      "h\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batchify' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-d03f57fb578a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#args.batch_size = lfactor(len(train_set))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batchify' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate train and test loader from our data\n",
    "train_text = prepare_text('./Brown_Leseprobe.txt')\n",
    "train_set = TextDataset(train_text, args.seq_len, args.offset)\n",
    "\n",
    "#args.batch_size = lfactor(len(train_set))\n",
    "train_loader = DataLoader(train_set, batch_size = args.batch_size, collate_fn=batchify, shuffle=False)\n",
    "\n",
    "for t in enumerate(train_loader):\n",
    "    print(t)\n",
    "\n",
    "test_text = prepare_text('./Brown_Leseprobe_test.txt')\n",
    "test_set = TextDataset(test_text, args.seq_len, args.offset)\n",
    "test_loader = DataLoader(test_set, batch_size = args.batch_size, shuffle=True)\n",
    "\n",
    "# set further parameters\n",
    "char_idx = train_set.char_idx\n",
    "idx_char = train_set.idx_char\n",
    "no_classes = train_set.no_classes\n",
    "input_shape = (args.seq_len, no_classes) # seq_len * nr. of unique characters \n",
    "\n",
    "# get len of data to determine the possible batch_size\n",
    "print(args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 29)\n",
      "LSTM_RNN(\n",
      "  (encoder): Embedding(81, 29)\n",
      "  (lstm): LSTM(29, 128, num_layers=2)\n",
      "  (linear): Linear(in_features=128, out_features=29)\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "print(input_shape)\n",
    "rnn = LSTM_RNN(no_classes)\n",
    "if args.cuda:\n",
    "    rnn.cuda()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the optimization algorithm\n",
    "optimizer = optim.RMSprop(rnn.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "<enumerate object at 0x7f16dd17df30>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'type' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-e5ae17150f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-275-b838604672fa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;31m# compute total loss over one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(\"data:\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run training and store history\n",
    "history = dict()\n",
    "history['loss_train'] = []\n",
    "history['loss_test'] = []\n",
    "\n",
    "# wie wir die accuracy machen, weiß ich noch nicht...\n",
    "#history['acc_train'] = []\n",
    "#history['acc_test'] = []\n",
    "print(args.batch_size)\n",
    "for epoch in range(10):\n",
    "    loss_train = train(rnn, epoch)        \n",
    "    history['loss_train'].append(loss_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3Xm8VWW9x/HPj0EmAQdStEDDIVETBRzScE5xgk1ahlGk\nZal5LfLerpqm2aC3UsvMBhucipu3QVAUZyVRMg9qg6A5YjgigiiDDM/9Y+0Th9PhcM4+Z5+19z6f\n9+u1X3vvtZ+19m8Jcr7neZ71rEgpIUmSVA5d8i5AkiTVLoOGJEkqG4OGJEkqG4OGJEkqG4OGJEkq\nG4OGJEkqG4OGJEkqG4OGJEkqG4OGJEkqG4OGJEkqG4OGpDaLiIkRsSYihuddi6TKYtCQ1F68cZKk\nf2PQkCRJZWPQkNQhIuJdEfHziHg5IpZFxKMR8ckm2n0sIh6OiDcjYnFE/CUizmjwebeIOD8iniwe\nZ0FE/DEiDunYM5LUEt3yLkBS7YuInsB9wBDgB8BzwEeAqyOif0rpB8V2HwJ+DdwBfLm4+1BgX+Dy\n4vuvAWcBPwX+DPQDRgLDgbs64HQktYJBQ1JH+BzwPuDjKaX/BYiIHwMzgG9ExC9SSm8DRwKLU0qH\nN3OsI4FpKaVTy120pLZz6ERSRzgCeLk+ZACklFaT9VJsDBxQ3LwI6BMRzQWNRcAuEbF9uYqV1H4M\nGpI6wjbAP5rYPgeI4ucAVwJPArdExAvFOR2NQ8dXgU2AJ4vzN74dEe8vV+GS2sagIalipJReA3YH\nxgBTgAOBWyPilw3a/BHYDjgR+CvwaWB2RJzU4QVL2iCDhqSO8DywQxPbhzb4HICU0qqU0rSU0ukp\npe2AnwCfjIghDdosSildk1L6ODAI+AtwQdmql1Qyg4akjnALMDAijq/fEBFdgf8AlpBdkUJEbNbE\nvn8tPvdoqk1KaSnwVP3nkiqLV51Iai8BfDoijmjis++TXXlydUSMZO3lrR8AvlC84gTgZ8UgcTfw\nT2Bb4HTgkZTSnGKbxyPiXqAOWAjsCRzH2stfJVWQSMlVgyW1TURMBH7RTJNBwDvAxcAxZGtfPAFc\nklK6rsFxxgGfJZunsQnwMllvyNdSSq8W25xNNodjR7JejOeBa4HvFq9kkVRBDBqSJKlsKmKORkSM\nioipETG/eAfIMRtov19E3F9cenhpRMyJiC92VL2SJKllKmWORh/gUeDnwO9b0P5tsmWM/1J8/UHg\npxHxVkrpZ2WrUpIktUrFDZ1ExBqgkFKa2sr9fge8lVKaWJ7KJElSa1XE0ElbRcQeZLPX7825FEmS\n1EBVB43iEsXLgYeAH6aUftlM294RMTwiendchZIkVb+2/AytlDkapfog2Q2Z9gH+JyKeSin9Zj1t\ndwdmki1V/Fajz6YDt5WvTEmSqsbhwOhG2zYGhgP7AQ+05mBVHTRSSvXLFv89IgaSLUG8vqCxbfF5\neBOf7Q98q12LkySp9mxLZwoajXSl+SWInwO4/vrrGTp0aDPNqsOkSZO47LLL8i6j3Xg+lauWzgU8\nn0pWS+cCtXU+c+bMYcKECVD8WdoaFRE0IqIPsD3ZEsYAQyJiGLAwpfRCRFwEbF1/RUlEnAbMA+YW\n2x8AnAl8r5mvWQ4wdOhQhg9vqlOjuvTv378mzqOe51O5aulcwPOpZLV0LlB751O0vLU7VETQAEYC\n9wCp+LikuP0a4CRgINkSxvW6ABeRdeGsAp4G/iul9NMOqleSJLVARQSNlNJ9NHMFTErpxEbvrwCu\nKHddkiSpbar68lZJklTZDBpVavz48XmX0K48n8pVS+cCnk8lq6Vzgdo7n1JV3BLk5RIRw4G6urq6\n9U7OmTdvHgsWLOjYwjqxAQMGMHjw4LzLkCRtwOzZsxkxYgTAiJTS7NbsWxFzNCrBvHnzGDp0KEuX\nLs27lE6jd+/ezJkzx7AhSTXMoFG0YMECli5dWjPrbFS6+muyFyxYYNCQpBpm0GikVtbZkCSpEjgZ\nVJIklY1BQ5IklY1BQ5IklY1BQ5IklY1Bo5O4+uqr6dKlC/Pmzcu7FElSJ2LQ6CQigojYcENJktqR\nQUOSJJWNQUOSJJWNQaMTu/LKK9l1113p2bMn7373uzn99NNZvHjxOm2eeuopjj32WLbaait69erF\noEGDGD9+PEuWLPlXmzvuuINRo0ax6aab0rdvX3baaSe+8pWvdPTpSJIqkCuDdlIXXHABF154IYcd\ndhinnXYaTzzxBFdeeSUPP/wwM2fOpGvXrqxcuZLDDjuMlStXcsYZZzBw4EDmz5/PzTffzKJFi+jb\nty+PP/44xxxzDLvvvjtf//rX6dGjB0899RQPPPBA3qcoSaoABo1OaMGCBVx88cWMHj2aW2655V/b\n3/e+9/Ef//EfXH/99UycOJHHH3+c5557jt/97neMGzfuX+3OPffcf72+4447WLlyJbfeeiubbrpp\nh56HJKnyGTRKtHQpzJ1b3u/YaSfo3bv9j3vnnXeycuVKvvjFL66z/eSTT+acc85h2rRpTJw4kf79\n+wMwffp0Ro8eTa9evf7tWJtssgkAf/jDHzjxxBO9skWStA6DRonmzoURI8r7HXV1UI77uz3//PMA\n7Ljjjuts7969O0OGDPnX59tuuy1nnnkml156Kddffz2jRo1izJgxTJgwgX79+gFw/PHH8/Of/5yT\nTz6Zs846i0MOOYQPf/jDHHfccYYOSZJBo1Q77ZQFgXJ/R96+853v8KlPfYopU6Zw++23c8YZZ3Dx\nxRcza9Ystt56a3r27MmMGTO45557mDZtGtOnT+c3v/kNhxxyCLfffrthQ5I6OYNGiXr3Lk9vQ0fY\nZpttSCnxxBNPsO222/5r+8qVK3n22Wf50Ic+tE77XXbZhV122YVzzjmHWbNmse+++/LjH/+YCy+8\n8F9tDjroIA466CC++93vctFFF3Huuedyzz33cPDBB3fUaUmSKpCXt3ZChx56KBtttBGXX375Ott/\n9rOf8eabb3L00UcDsGTJElavXr1Om1122YUuXbqwYsUKAN54441/O/6wYcNIKf2rjSSp87JHoxMa\nMGAAZ599NhdeeCGjR49mzJgxzJ07lx/96EfstddefPzjHwfg7rvv5vTTT+cjH/kIO+64I6tWreLa\na6+lW7duHHfccQBceOGFzJgxg6OOOoptttmGV155hR/96EcMHjyYD37wg3mepiSpAhg0Oqnzzz+f\nLbbYgiuuuIIvfelLbLbZZpxyyil885vfpGvXrkDWMzF69Ghuvvlm5s+fT+/evRk2bBjTp09nzz33\nBGDs2LE8//zz/PKXv2TBggUMGDCAAw88kAsuuIC+ffvmeYqSpApg0OgkJk6cyMSJE9fZduqpp3Lq\nqaeud59tt92Wq666qtnjHnjggRx44IHtUaIkqQY5R0OSJJWNQUOSJJWNQUOSJJWNQUOSJJWNQUOS\nJJWNQUOSJJWNQUOSJJWNQUOSJJWNC3Y1MmfOnLxL6BT87yxJnYNBo2jAgAH07t2bCRMm5F1Kp9G7\nd28GDBiQdxmSpDIyaBQNHjyYOXPmsGDBgrxL6TQGDBjA4MGD8y5DklRGBo0GBg8e7A8+SZLakZNB\nJUlS2Rg0JElS2Rg0JElS2Rg0JElS2VRE0IiIURExNSLmR8SaiBizgfbjIuL2iHg1IhZHxAMRcVhH\n1StJklqmIoIG0Ad4FDgNSC1ovz9wO3AEMBy4B7gpIoaVrUJJktRqFXF5a0ppOjAdICKiBe0nNdr0\nlYgYCxwDPNb+FUqSpFJUSo9GmxTDSV9gYd61SJKktWoiaAD/RTb8csOGGq5YUf5iJElSpiKGTtoi\nIk4AzgPGpJQ2uH74ySdPYsiQ/utsGz9+POPHjy9ThZIkVY/JkyczefLkdbYtXry45ONFSi2Ze9lx\nImINUEgpTW1B248BPwOOK87zaK7tcKBu7Ng6brxxePsUK0lSJzB79mxGjBgBMCKlNLs1+1bt0ElE\njAd+DnxsQyGjofvug9Wry1eXJElaqyKCRkT0iYhhEbF7cdOQ4vtBxc8viohrGrQ/AbgGOBP4c0Rs\nWXz029B3LVoEDz5YjrOQJEmNVUTQAEYCjwB1ZOtoXALMBr5W/HwgMKhB+5OBrsAPgRcbPL63oS/a\nfHO48cZ2q1uSJDWjIiaDppTuo5nQk1I6sdH7g0r9rgMOgD/8Ab7zHdjwih2SJKktKqVHo8McdBA8\n8wz87W95VyJJUu3rdEFjzz2hXz+HTyRJ6gidLmh07w5HHmnQkCSpI3S6oAFQKMDs2TBvXt6VSJJU\n2zpl0DjiiKxnw14NSZLKq1MGjX794JBDDBqSJJVbpwwaAOPGwYwZ8PrreVciSVLt6rRBY8wYWLMG\npk3LuxJJkmpXpw0aAwfCPvtki3dJkqTy6LRBA7KrT267DZYuzbsSSZJqU6cOGuPGwbJlcMcdeVci\nSVJt6tRBY4cdYOedvfpEkqRy6dRBA7Lhk5tuglWr8q5EkqTaY9AoZJe43n9/3pVIklR7On3QGDEC\n3v1uh08kSSqHTh80unTJejVuvBFSyrsaSZJqS6cPGpAFjeefh8cey7sSSZJqi0EDOOAA6N/fxbsk\nSWpvBg2yO7kefbTzNCRJam8GjaJx4+Avf4Fnnsm7EkmSaodBo+jww6FHD5gyJe9KJEmqHQaNoo03\nhg99yHkakiS1J4NGA4UCzJwJr76adyWSJNUGg0YDxxyTPd98c751SJJUKwwaDWyxBey3n1efSJLU\nXgwajRQKcPvt8NZbeVciSVL1M2g0MnYsrFgBt92WdyWSJFU/g0Yj220H73+/wyeSJLUHg0YTxo3L\nJoSuXJl3JZIkVTeDRhMKBVi0CGbMyLsSSZKqm0GjCbvvDoMHu3iXJEltZdBoQkTWq3HjjZBS3tVI\nklS9DBrrUSjA/PlQV5d3JZIkVS+DxnqMGgWbbebVJ5IktYVBYz26dcuWJHeehiRJpTNoNKNQgMcf\nhyefzLsSSZKqk0GjGYcdBr16wZQpeVciSVJ1Mmg0o3dvOPxw52lIklQqg8YGFArw4IPw8st5VyJJ\nUvUxaGzA0Udn62pMnZp3JZIkVZ+KCBoRMSoipkbE/IhYExFjNtB+YET8KiKeiIjVEXFpuWrbfHPY\nf3+HTyRJKkVFBA2gD/AocBrQkrU4ewCvAl8v7ldWhQLcdRe8+Wa5v0mSpNpSEUEjpTQ9pfTVlNIU\nIFrQ/vmU0qSU0vVA2X/8FwrwzjswfXq5v0mSpNpSEUGj0m2zDeyxh4t3SZLUWgaNFioUYNo0WLEi\n70okSaoeBo0WKhRgyRK49968K5EkqXp0y7uAjjZp0iT69++/zrbx48czfvz4Zvd7//thyJDs6pPD\nDy9nhZIk5Wfy5MlMnjx5nW2LFy8u+XiRUksu8ug4EbEGKKSUWrRyRUTcAzySUvrSBtoNB+rq6uoY\nPnx4SbWdeSZMngz//Cd0sS9IktRJzJ49mxEjRgCMSCnNbs2+FfHjMiL6RMSwiNi9uGlI8f2g4ucX\nRcQ1jfapb78x8K7i+6HlrLNQgJdegoceKue3SJJUOypl6GQkcA/ZGhoJuKS4/RrgJGAgMKjRPo+w\nds2N4cAJwPPAkHIVue++MGBANnyyzz7l+hZJkmpHRQSNlNJ9NNO7klI6sYltHd4b07UrjBmTBY2L\nL+7ob5ckqfpUxNBJNRk3Dp54AubOzbsSSZIqn0GjlQ45BPr0cfEuSZJawqDRSr16wejR3mRNkqSW\nMGiUoFDIrjyZPz/vSiRJqmwGjRIcdRR06wZTW7TShyRJnZdBowSbbgoHHug8DUmSNsSgUaJCAe65\nBxYtyrsSSZIql0GjRGPGwKpVcMsteVciSVLlMmiUaNAgGDnSq08kSWqOQaMNxo2DW2+F5cvzrkSS\npMpk0GiDQgHeegvuuivvSiRJqkwGjTYYOhR22MHhE0mS1seg0QYRWa/G1KmwenXe1UiSVHkMGm00\nbhy8+irMmpV3JZIkVR6DRhvtvTdsuaWLd0mS1BSDRht16QJjx2bzNFLKuxpJkiqLQaMdFArw9NPw\n97/nXYkkSZXFoNEODj4Y+vb16hNJkhozaLSDHj3gyCOdpyFJUmMGjXZSKMDs2TBvXt6VSJJUOQwa\n7eSII6B7d5gyJe9KJEmqHAaNdtK/fzZXw3kakiStZdBoR+PGwX33wcKFeVciSVJlMGi0ozFjsqXI\nb74570okSaoMBo12tNVWsM8+Dp9IklTPoNHOCgWYPh2WLs27EkmS8mfQaGeFAixbBnfemXclkiTl\nz6DRzt73Phg61MW7JEkCg0ZZFApw002walXelUiSlC+DRhkUCvD66zBzZt6VSJKUL4NGGYwcCVtv\n7dUnkiQZNMqgS5esV+PGGyGlvKuRJCk/Bo0yKRTguefgscfyrkSSpPwYNMrkgAOy+584fCJJ6swM\nGmWy0UZw1FEGDUlS52bQKKNCIRs6efbZvCuRJCkfBo0yGj0aevSwV0OS1HmVFDQiYmJEHNXg/bcj\nYlFEPBAR27RfedWtb1849FCDhiSp8yq1R+McYBlARHwA+DzwZWABcFn7lFYbCgW4/3547bW8K5Ek\nqeOVGjQGAU8VXxeA36WUfgqcDYxqj8JqxTHHZGtp3Hxz3pVIktTxSg0abwGbF18fBtxRfL0c6NXW\nomrJllvCfvt5kzVJUudUatC4A/hZRPwM2BG4pbh9F+C51h4sIkZFxNSImB8RayJiTAv2OTAi6iJi\neUQ8GRETW/u9HaVQgNtvh7feyrsSSZI6VqlB4/PAg8C7gGNTSq8Xt48AJpdwvD7Ao8BpwAYX7Y6I\nbYGbgbuAYcD3yYLPh0r47rIbOxZWrMjChiRJnUm3UnZKKS0CTm9i+/klHm86MB0gIqIFu5wKPJNS\n+nLx/RMR8UFgEmuHcSrG9tvDrrtmV598+MN5VyNJUscp9fLW0cUf7PXvPx8Rj0bEryNi0/Yrb732\nAe5stO024AMd8N0lKRSyCaErV+ZdiSRJHafUoZPvAP0AIuL9wCVk8zTeC1zaPqU1ayDwSqNtrwD9\nIqJHB3x/q40bB2+8ATNm5F2JJEkdp9Sg8V7g8eLrY4GbU0rnkM3dOKI9Cqs1e+wBgwa5eJckqXMp\naY4G8A7Qu/j6UODa4uuFFHs6yuxlYMtG27YE3kwprWhux0mTJtG/f/91to0fP57x48e3b4WNRGTD\nJ3/4A1x+efZekqRKM3nyZCZPXve6jsWLF5d8vEhpgxd5/PtOEVOBjYCZwHnAe1NK8yPiMOCKlNKO\nJRcUsQYopJSmNtPmYuCIlNKwBtt+DWySUjpyPfsMB+rq6uoYPnx4qeW1yd13wyGHwMMPw4gRuZQg\nSVKrzZ49mxHZD64RKaXZrdm31KGT04FVwHHAqSml+cXtR1C8eqQ1IqJPRAyLiN2Lm4YU3w8qfn5R\nRFzTYJcfF9v8T0S8LyJOK9bSEfNDSrb//rDppi7eJUnqPEq9vHUecHQT2yeVWMdI4B6yNTQS2eRS\ngGuAk8gmfw5q8D3PFW/qdhlwBvBP4NMppcZXolSUbt2yJclvvBG+8Y28q5EkqfxKnaNBRHQlu8/J\n0OKmvwNTU0qrW3uslNJ9NNO7klI6sYltM8gWCKsqhQJcey384x+www55VyNJUnmVuo7G9sAcskmg\nHy4+rgf+HhHbtV95teeww6BnT5gyJe9KJEkqv1LnaFwOPA0MSikNTykNBwYDzxY/03r06ZOFDedp\nSJI6g1KDxgHAl1NKC+s3FO93clbxMzVj3Dh48EF4+eW8K5EkqbxKDRorgL5NbN+YbI0NNePoo7N1\nNG66Ke9KJEkqr1KDxs3ATyNi71hrH7LLTte7/oUyAwbAqFGuEipJqn2lBo0zyOZoPAgsLz4eAJ4C\nvtg+pdW2QgHuvBOWLMm7EkmSyqekoJFSWpRSGgvsSLZQ1nHAjimlccVbyGsDCgV45x249da8K5Ek\nqXxavI5GRGxo1c2DongDj5TSl9pSVGew7baw++7Z8MlHP5p3NZIklUdrFuzao4XtWn/zlE6qUIBL\nL816NjbaKO9qJElqfy0OGimlg8pZSGdUKMAFF8C992Zra0iSVGtKnQyqdrDbbtkQiot3SZJqlUEj\nRxHZ4l1TpsCaNXlXI0lS+zNo5KxQgJdegj//Oe9KJElqfwaNnO27b7aAl4t3SZJqkUEjZ926wTHH\nGDQkSbXJoFEBxo2DuXOzhyRJtcSgUQEOPRR697ZXQ5JUewwaFaBXLxg92qAhSao9Bo0KUSjAn/4E\nL76YdyWSJLUfg0aFOOoo6No1W1NDkqRaYdCoEJttBgce6PCJJKm2GDQqSKEAd98NixblXYkkSe3D\noFFBxo6FVavg1lvzrkSSpPZh0KgggwbBiBHeZE2SVDsMGhVm3LisR2P58rwrkSSp7QwaFaZQgLfe\nyuZqSJJU7QwaFWbnnWH77b36RJJUGwwaFSYi69WYMgVWr867GkmS2sagUYEKBXj1VZg1K+9KJElq\nG4NGBdpnH9hyS4dPJEnVz6BRgbp2hTFjsstcU8q7GkmSSmfQqFCFAjz9NDz+eN6VSJJUOoNGhTr4\nYNh4YxfvkiRVN4NGherZE4480nkakqTqZtCoYIUC1NXBCy/kXYkkSaUxaFSwI4+E7t2zNTUkSapG\nBo0K1r8/HHSQwyeSpOpl0KhwhQLcey8sXJh3JZIktZ5Bo8KNHZstRT5tWt6VSJLUegaNCrf11rD3\n3g6fSJKqk0GjChQKMH06LFuWdyWSJLVOxQSNiPh8RDwbEcsiYlZE7NmC9o9HxNKImBMRn+ioWjta\noQBLl8Idd+RdiSRJrVMRQSMijgcuAc4H9gAeA26LiAHraX8q8E3gq8DOwAXADyPiqA4puIPttFP2\ncPhEklRtKiJoAJOAn6SUrk0pzQVOAZYCJ62n/YRi+9+mlJ5LKf0G+Cnw3x1TbscrFGDqVFi1Ku9K\nJElqudyDRkR0B0YAd9VvSykl4E7gA+vZrQewvNG25cBeEdG1HHXmrVCA11+HBx7IuxJJklou96AB\nDAC6Aq802v4KMHA9+9wGfCYihgNExEjg00D34vFqzp57wlZbeZM1SVJ16ZZ3ASX6OrAl8GBEdAFe\nBq4GvgysaW7HSZMm0b9//3W2jR8/nvHjx5en0nbSpUvWq3HjjXDppRCRd0WSpFo0efJkJk+evM62\nxYsXl3y8yEYp8lMcOlkKHJtSmtpg+9VA/5TSuGb27UoWOF4CPgdcnFLaZD1thwN1dXV1DB8+vB3P\noOPcfjscfjg8+igMG5Z3NZKkzmL27NmMGDECYERKaXZr9s196CSltBKoAw6p3xYRUXzf7IyElNLq\nlNKLxTkdHwNuKmeteTvwQOjXz6tPJEnVI/egUXQpcHJEfDIidgJ+DPQmGw4hIi6KiGvqG0fEDhHx\n8YjYPiL2ioj/BXYBvpJD7R1mo43gqKMMGpKk6lERQSOldAPwn8CFwCPAbsDhKaXXik0GAoMa7NIV\nOBN4lGxi6EbAvimleR1WdE4KhWzo5Nln865EkqQNq5jJoCmlK4Er1/PZiY3ezwWqc6JFGx1xRNaz\nMWUKfPGLeVcjSVLzKqJHQy3Xty8ceij8/vd5VyJJ0oYZNKrQCSfAH/8In/wkLFmSdzWSJK2fQaMK\nnXACXHtttnjXHnvAQw/lXZEkSU0zaFShCPjEJ7JJoZtvDvvtBxddBKtX512ZJEnrMmhUse22g/vv\nh//6L/jKV+BDH4L58/OuSpKktQwaVa57d/jWt+Cuu+DJJ2G33VxnQ5JUOQwaNeKgg+Cxx2D//WHc\nODjlFFi6NO+qJEmdnUGjhmy+eXbZ609+kk0WHTkyCx+SJOXFoFFjIuCzn4WHH86GVfbaC77/fcj5\n3nmSpE7KoFGjdt4Z/vQnOO20bAXRo46CV1/NuypJUmdj0KhhPXvCZZfBLbdAXV02UfS22/KuSpLU\nmRg0OoEjjoC//CVb3Gv0aDjzTFixIu+qJEmdgUGjk9hyS5g2LevhuOIK2GcfmDs376okSbXOoNGJ\ndOmSzdeYNQuWL4fhw+Gqq5woKkkqH4NGJ7THHtlVKZ/4RHaFynHHwcKFeVclSapFBo1Oqk+fbL2N\n3/0O7rkHhg2D++7LuypJUq0xaHRyH/5wNlF0u+2y1UXPPRdWrsy7KklSrTBoiPe8J7tXyje+ARdf\nDKNGwTPP5F2VJKkWGDQEQNeucM45MHMmvPYa7L47/OpXeVclSap2Bg2tY++94ZFHYOxYmDAhmzD6\n5pt5VyVJqlYGDf2bfv3guuuyx5QpWe/GrFl5VyVJqkYGDa3XhAnw6KOwxRbwwQ/Ct74Fq1fnXZUk\nqZoYNNSsIUPgj3+Es8/Orkg55BB44YW8q5IkVQuDhjaoe3f4+tez9Taefjpbc+P3v8+7KklSNTBo\nqMUOOAAeeyxbb+PYY7NVRd9+O++qJEmVzKChVtlsM/jtb7N7pPzqVzByZDaPQ5Kkphg01GoR8JnP\nQF0d9OyZXRJ72WWwZk3elUmSKo1BQyXbaafsstfTT4cvfQmOOgpeeSXvqiRJlcSgoTbp0QMuuQSm\nT88W+tptN7j11ryrkiRVCoOG2sXhh2c3Zxs5Eo48Er74RVi+PO+qJEl5M2io3WyxBdx8M3z/+/Cj\nH8E++8CcOXlXJUnKk0FD7SoCzjgD/vxneOcdGDECfvITSCnvyiRJeTBoqCx22w0efhgmToRTTsnW\n3Xj99byrkiR1NIOGyqZ372wI5Q9/gPvuy1YUveeevKuSJHUkg4bKrlDIJoruuGN2r5RzzoGVK/Ou\nSpLUEQwa6hDvfjfccUd2B9jvfCe7G+zTT+ddlSSp3Awa6jBdu8JZZ8HMmdl8jd13h+uuc6KoJNUy\ng4Y63F57ZYt7HXssfPKTMGECLFyYd1WSpHIwaCgXffvC1VfDr3+drb2xxRaw777w1a9mE0dXrMi7\nQklSezBoKFfjx8PcuXDllfCe92TPBx4Im24Ko0dn8zkeecQbtklStaqYoBERn4+IZyNiWUTMiog9\nN9D+4xHxaES8HREvRsTPI2KzjqpX7WerreCzn4UbboBXX4XZs+HCC7PPLrgAhg/Pejw++tFs8a+n\nnnJehyQd40c7AAAR+0lEQVRVi4oIGhFxPHAJcD6wB/AYcFtEDFhP+/2Aa4CrgJ2B44C9gJ92SMEq\nmy5dYI894D//M7tR28KFcO+9cNppMH8+fP7zsMMO8N73wqc/DZMne8dYSapkFRE0gEnAT1JK16aU\n5gKnAEuBk9bTfh/g2ZTSD1NKz6eUHgB+QhY2VEN69IADDsh6OGbOzILHTTdla3M89BCccAIMHJit\nRDppEkybBkuW5F21JKle7kEjIroDI4C76rellBJwJ/CB9ez2IDAoIo4oHmNL4CPAtPJWq7z16wdH\nHw3f+x789a/w0kvwq19ld439/e+zzzbbLFun4/zzYcaM7J4rkqR85B40gAFAV6BxB/grwMCmdij2\nYEwAfhMR7wAvAW8Ap5exTlWggQOzXo1f/AKeew7+8Q/4wQ+yeR9XXJH1hmy6KRxxBFxyCTz6qBNL\nJakjVULQaLWI2Bn4PnABMBw4HHgv2fCJOqkI2H777CZu//d/8NprUFeX9WysWQPnnZfN/9hySzj+\neLjqKnjmmbyrlqTaFinn6fvFoZOlwLEppakNtl8N9E8pjWtin2uBnimljzbYth/wR2CrlNK/TQ+M\niOFA3f7770///v3X+Wz8+PGMHz++nc5IlWrFCnjwQbjrLrjzzuxW9qtXw7bbwqGHZvdhOfjg7AoX\nSeqsJk+ezOTJk9fZtnjxYmbMmAEwIqU0uzXHyz1oAETELOBPKaUvFN8HMA+4PKX0nSba/xZ4J6V0\nQoNtHwDuB96dUnq5iX2GA3V1dXUMHz68TGeiarJ4cbY4WH3wePzxbPtuu60NHvvvDxtvnG+dkpS3\n2bNnM2LECCghaHQrT0mtdilwdUTUAQ+RXYXSG7gaICIuArZOKU0str8J+GlEnALcBmwNXEYWVv4t\nZEhN6d8fxozJHgAvvgh3350FjxtugEsvhW7dYJ99stBx6KGw997QvXu+dUtSNamIoJFSuqG4ZsaF\nwJbAo8DhKaXXik0GAoMatL8mIjYGPg98F1hEdtXKWR1auGrK1ltn912ZMCFbEOwf/1jb23H55fC1\nr0GfPtkE0/rgseuu2dofkqSmVcTQSUdw6ERtsXp1thR6ffC4/35Yvhze9a5sXkf9UMt735t3pZLU\n/mph6ESqaF27Zmt1jBwJ//3fWch44IEseNx1F3zuc9mVLUOGZMFj6FAYPBi22SZ73mKL7KoYSeps\nDBpSCXr2zALFwQfDN78JixZlE0vvvDN7/vWvYenSte179IBBg9YGj4YhZPDg7LOePfM7H0kqF4OG\n1A422QTGjs0ekM3xWLgQ5s3LHs8/v/b13/8Ot94KLzeatrzllmuDR+Mgss02sPnm9opIqj4GDakM\nIrJgsPnm2SJhTVmxAv75z3VDSH0omTYte718+dr2vXqtP4QMHgzveQ9stFHHnJ8ktZRBQ8pJjx6w\n3XbZoykpZaubNg4h8+ZlS6lPnQqvvrq2fUS2JPv6hmcGD86WY7dXRFJHMmhIFSoim0S6xRbZJNSm\nLFsGL7zQ9BBNXV32WcObym28cfPDM1tv7TohktqXQUOqYr16wY47Zo+mrFmT9Xo0DiHz5mVLsP/u\nd/D662vbd+mShY2GIWSrrbIhme7ds0fD1w0frd3u+iNS52DQkGpYly7ZcMrAgbDXXk23efvtdQNI\nw1Aya1Y2aXXlSli1qn1r69q17WGl1O3dumWP+tfre27NZ127OiwlNcWgIXVyffpk634MHdp8u5Sy\nwNHU4513Onb7O+9kAamU45RzjcL6ANJe4aUln/Xrl131tOmm2XPD13372nOk/Bk0JLVIRNYjUO1X\ntqxZs7aHpv654esNPbd326a2LVvWsrbvvANLlmShqyldumT39GkcQBq/Xt9nvXrZS6O2M2hI6lS6\ndMmu+OnRI+9K2s8772R3I160CN54I3uufzR8X/96/vy1r994IwstTeneff3hpCVBxYnFAoOGJFW9\njTbK7rvzrne1ft+Ush6UDYWT+tevvZbdcLD+/eLFWS9RU3r3bl1Q6d8/G+7ZeOPs0aePQz+1wKAh\nSZ1YRBYIevfOrjhqrTVr4K23WtaTsmhRNtH4scfWvl+ypPnj9+mzNnjUPxqGkabeN9emd2/DS0cz\naEiSStalSzYhtV+/7JLo1lq1au2wz6JFWWipfyxZsu77htvefBNefPHf2yxbtuHvrA8vrQkozW2r\npfCSUhYeGz+35L/r+hg0JEm56dZt7XL97WH16vWHkw0FmMWLs/krjds0vBVAUyL+veelb9/s3Nb3\ng7sSn8t1RZZBQ5JUM7p2zeZ69O/ffsdctSq7sqelgaX+edWqrKcjovqfn3sOzjuvtP9+Bg1JkprR\nrVv7h5dqM3t26UGjRkaVJElSJTJoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFo\nSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKk\nsjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksjFoSJKksqmYoBERn4+IZyNiWUTM\niog9m2n7y4hYExGri8/1j792ZM15mjx5ct4ltCvPp3LV0rmA51PJaulcoPbOp1QVETQi4njgEuB8\nYA/gMeC2iBiwnl3OAAYCWxWf3wMsBG4of7WVodb+Ans+lauWzgU8n0pWS+cCtXc+paqIoAFMAn6S\nUro2pTQXOAVYCpzUVOOU0pKU0qv1D2AvYBPg6o4qWJIkbVjuQSMiugMjgLvqt6WUEnAn8IEWHuYk\n4M6U0gvtX6EkSSpV7kEDGAB0BV5ptP0VsmGRZkXEVsARwFXtX5okSWqLbnkX0A4+BbwBTNlAu54A\nn/nMZ+jbt+86Hxx++OGMHj26LMWVy+LFi5k9e3beZbQbz6dy1dK5gOdTyWrpXKB6z2f69Oncdttt\n62xbsmRJ/cuerT1eZKMU+SkOnSwFjk0pTW2w/Wqgf0pp3Ab2fxKYmlL6zw202xeY2faKJUnqtPZL\nKT3Qmh1y79FIKa2MiDrgEGAqQERE8f3lze0bEQcC2wE/b8FXPUo2F0SSJJVmbmt3yD1oFF0KXF0M\nHA+RXYXSm+JVJBFxEbB1Smlio/0+DfwppTRnQ1+QUloKVF8fliRJVawigkZK6YbimhkXAluS9T4c\nnlJ6rdhkIDCo4T4R0Q8YR7amhiRJqkC5z9GQJEm1qxIub5UkSTXKoCFJksqmUwSN1tywrZJFxKiI\nmBoR84s3kRuTd01tERFnR8RDEfFmRLwSEX+IiB3zrqsUEXFKRDwWEYuLjwcioroWZ2lGRJxV/Dt3\nad61lCIizm90A8Y1EfF43nWVKiK2jojrImJBRCwt/t0bnnddpSj+29z4z2ZNRPwg79pKERFdIuLr\nEfFM8c/mqYg4N++6ShURG0fE9yLiueL53B8RI1tzjJoPGiXcsK2S9SGbKHsaUAuTa0YBPwD2Bg4F\nugO3R0SvXKsqzQvAfwPDyS6jvhuYEhFDc62qHRSD+WfJ/t+pZn8jm2w+sPj4YL7llCYiNiFbE2gF\ncDgwFDiTbOHCajSStX8mA4EPkf37Vq03yTwL+BzZv9M7AV8GvhwRp+daVel+TrbcxMeBXYE7gDuL\nq3K3SM1PBo2IWWSXwH6h+D7IfihcnlL6dq7FtUFErAEKDRc5q3bF8PcqsH9K6f6862mriHgd+M+U\n0i/zrqVUEbExUAecCpwHPJJS+lK+VbVeRJwPjE0pVeVv/Q1FxMXAB1JKB+RdSzlExPeAI1NK1dq7\neRPwckrp5AbbfgssTSl9Mr/KWi8iegJLgGNSStMbbH8YuCWl9NWWHKemezTa6YZt6jibkP0mszDv\nQtqi2HX6MbK1YB7Mu542+iFwU0rp7rwLaQc7FIcdn46I6yNi0IZ3qUjHAA9HxA3FIcfZEfGZvItq\nD8V/sz9OyxZhrFQPAIdExA4AETEM2A+4JdeqStON7F5kKxptX0YregQrYh2NMmruhm3v6/hytD7F\nnqbvAfenlKpy7DwidiULFvW/BYxLKbV6Fb1KUQxLu5N1bVe7WWT3RXoC2Aq4AJgREbumlN7Osa5S\nDCHrYboE+CawF3B5RKxIKV2Xa2VtNw7oD1yTdyFtcDHQD5gbEavJfqH/Skrpf/Mtq/VSSm9FxIPA\neRExl+xn5wlkv6j/o6XHqfWgoepxJbAzWfKvVnOBYWT/UB4HXBsR+1dj2IiI95AFv0NTSivzrqet\nUkoN7xD1t4h4CHge+ChQbUNbXYCHUkrnFd8/Vgy5pwDVHjROAm5NKb2cdyFtcDzZD+OPAY+ThfXv\nR8SLVRoEJwC/AOYDq8hW2P41rbilR60HjQXAarIJYA1tCVTzX+SaEhFXAEcCo1JKL+VdT6lSSquA\nZ4pvH4mIvYAvkP32WW1GAO8CZhd7myDrHdy/OKmtR6riCV4ppcXFGzJun3ctJXgJaHzbhTnAh3Oo\npd1ExGCySeGFvGtpo28DF6WU/q/4/u8RsS1wNlUYBFNKzwIHFSfp90spvRIR/8vaf+s2qKbnaBR/\nE6u/YRuwzg3bWnX3OZVHMWSMBQ5KKc3Lu5521gXokXcRJboTeD/Zb2PDio+HgeuBYdUcMuBfk1y3\nJ/uhXW1m8u9Dv+8j66GpZieRdc1X41yGhnqT/YLb0Bqq/OdtSmlZMWRsSna1040t3bfWezRgAzds\nqyYR0YfsH8f63zCHFCcaLUwpvZBfZaWJiCuB8cAY4O2IqO95WpxSWp5fZa0XEd8CbgXmAX3JJrQd\nAByWZ12lKs5bWGeuTES8DbzekpsYVpqI+A5wE9kP43cDXwNWApPzrKtElwEzI+JssktA9wY+A5zc\n7F4VrPgL4KeAq1NKa3Iup61uAs6NiH8Cfye75H0S8LNcqypRRBxG9jPnCWAHsh6bx2nFz9CaDxot\nuGFbNRkJ3EN2ZUYimwwG2cSpk/Iqqg1OITuPexttPxG4tsOraZstyP4ctgIWA38BDquRqzXqVXMv\nxnvIxpU3B14D7gf2SSm9nmtVJUgpPRwR48gmHZ4HPAt8oRonGzZwKNmNM6ttvkxTTge+TnbF1hbA\ni8CPituqUX/gIrKAvhD4LXBuSqlxr8161fw6GpIkKT9VPWYkSZIqm0FDkiSVjUFDkiSVjUFDkiSV\njUFDkiSVjUFDkiSVjUFDkiSVjUFDkiSVjUFDUtWKiAMiYk1E9Mu7FklNM2hIqnYubyxVMIOGJEkq\nG4OGpJJF5uyIeCYilkbEIxFxbPGz+mGNIyPisYhYFhEPRsQujY5xbET8LSKWR8SzEfGlRp9vFBH/\nExHzim2ejIgTG5UyMiL+HBFvR8TMiNihzKcuqYUMGpLa4hxgAvBZYGeyW5hfFxGjGrT5NtltskeS\n3Tl1akR0BYiIEcBvyO6suitwPvD1iPhkg/2vA44nuyvmTmS3RH+rwecBfKP4HSOAVcAv2vUsJZXM\nu7dKKklEbER22+hDUkp/arD9KqAXcBVwD/DRlNJvi59tCvwTmJhS+m1EXA8MSCmNbrD//wBHppTe\nHxE7AnOL33FPEzUcANxd/Pze4rYjgJuBXimld8pw6pJawR4NSaXaHugN3BERS+ofwCeA7YptEjCr\nfoeU0hvAE8DQ4qahwMxGx50J7BARAQwj66GYsYFa/trg9UvF5y1adzqSyqFb3gVIqlobF5+PBF5s\n9NkKsiDSVsta2G5lg9f13bT+IiVVAP9HlFSqx8kCxTYppWcaPeYX2wSwT/0OxaGTHYv7AswB9mt0\n3A8CT6ZsXPevZP9OHVDG85BURvZoSCpJSumtiPgucFlxcuf9QH+y4LAYmFds+tWIWAi8CnyTbELo\nlOJnlwAPRcS5ZJNC9wU+D5xS/I7nI+Ja4BcR8QXgMWAbYIuU0v8VjxFNlNfUNkk5MGhIKllK6byI\neBU4CxgCLAJmA98CupINY5wFfJ9sKOUR4JiU0qri/o9ExEeBC4FzyeZXnJtSuq7B15xSPN4Pgc3J\nAsy3GpbRVGntdY6S2sarTiSVRYMrQjZNKb2Zdz2S8uEcDUnl5BCG1MkZNCSVk12mUifn0IkkSSob\nezQkSVLZGDQkSVLZGDQkSVLZGDQkSVLZGDQkSVLZGDQkSVLZGDQkSVLZGDQkSVLZGDQkSVLZ/D9+\nVuf+yIAt+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16dccacda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try a prediction\n",
    "\n",
    "#testdata = Variable(torch.from_numpy(test_set.data[0])) # get first element from the test set\n",
    "#truth = test_set.target[0]\n",
    "#print(testdata,truth)\n",
    "\n",
    "#prediction = rnn(testdata)\n",
    "## dann muss man hier noch auf die sizes achten, ach verdammt\n",
    "#prepare_input(\"This is an example of input for our LSTM\".lower(), train_set.data, char_idx)\n",
    "#print(predict_completions(seq, 5))\n",
    "\n",
    "def plotLineData(header, yLabel, firstData, firstLabel, firstColor='b', xLabel='epoch'):\n",
    "    plt.plot(firstData, color=firstColor)\n",
    "    plt.title(header)\n",
    "    plt.ylabel(yLabel)\n",
    "    plt.xlabel(xLabel)\n",
    "    plt.legend([firstLabel], loc='upper left')\n",
    "    plt.show()\n",
    "plotLineData(\"Loss\", \"loss\", history['loss_train'], \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "[-0.11601484 -0.06698944 -0.14379781 -0.20794013 -0.05701545 -0.09788888\n",
      " -0.24705899 -0.17627189 -0.04789039  0.00329647 -0.12827204 -0.19894782\n",
      " -0.21370783 -0.21884665 -0.01429991 -0.04381794 -0.12843238 -0.04341763\n",
      " -0.01838353 -0.18709238 -0.12128408 -0.16231658 -0.22151829 -0.23498613\n",
      " -0.2867972  -0.16310108 -0.18330958 -0.23249578 -0.21914572]\n",
      "(29,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marvin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.init_hidden(1)\n",
    "test = \"elerregend steilen H\"\n",
    "predict_completion(rnn, test.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
