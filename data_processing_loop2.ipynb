{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- encoding: iso-8859-15 -*-\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Import other python files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration / parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_config(config_path = \"config.txt\", args = dict()):\n",
    "    with open(config_path) as source:\n",
    "        for line in source:\n",
    "            line = line.strip()\n",
    "            argLong, valueLong = line.split('=')\n",
    "            arg = argLong.strip()\n",
    "            value = valueLong.strip()\n",
    "            if value == 'True':\n",
    "                value = True\n",
    "            elif value == 'False':\n",
    "                value = False\n",
    "            elif '.' in value:\n",
    "                value = float(value)\n",
    "            else:\n",
    "                value = int(value)\n",
    "            args[arg] = value\n",
    "    return edict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuda': False, 'seq_len': 40, 'clip': 1, 'lr': 0.1, 'offset': 1, 'batch_size': 16, 'hidden_size': 128, 'num_layers': 1}\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "print(args)\n",
    "#args.batch_size = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(textsource):\n",
    "    text = ''\n",
    "    with open(textsource, encoding=\"utf8\") as txtsource:\n",
    "        for line in txtsource:\n",
    "            line = line.strip().lower()\n",
    "            line = line.replace(',', '').replace('.', '')\n",
    "            line = line.replace('»', '').replace('«', '')\n",
    "            line = line.replace('\"', '').replace('!', '')\n",
    "            line = line.replace('’', '').replace('*', '')\n",
    "            line = line.replace(u'\\ufeff', '')\n",
    "            text += ' ' + line\n",
    "    text = text[:16020] #### nachher wieder rauslöschen!!!\n",
    "    return text\n",
    "# Chevrons müssen noch weg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_len, offset, char_idx, idx_char):\n",
    "      \n",
    "    # Define training samples by splitting the text\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - seq_len, offset):\n",
    "        sentences.append(text[i: i + seq_len])\n",
    "        next_chars.append(text[i + seq_len])\n",
    "\n",
    "    #print('sentences', sentences)    \n",
    "    #print('next_chars', next_chars)\n",
    "    print('nr training samples', len(sentences))\n",
    "    \n",
    "    # Generate features and labels using one-hot encoding\n",
    "    X = np.zeros((len(sentences), seq_len, len(chars)), dtype='f')\n",
    "    y = np.zeros((len(sentences)))\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for j, char in enumerate(sentence):\n",
    "            X[i, j, char_idx[char]] = 1\n",
    "        y[i] = char_idx[next_chars[i]]\n",
    "        \n",
    "    #print('next_chars: ' + str(next_chars[0]))\n",
    "    #print('out: ' + str(X[0, :, :]))\n",
    "    #print('target: ' + str(y[0]))\n",
    "        \n",
    "    return X, y, char_idx, idx_char, no_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    ''' A text dataset class which implements the abstract class torch.utils.data.Dataset. '''\n",
    "    def __init__(self, text, seq_len, offset, char_idx, idx_char):\n",
    "        self.data, self.target, self.char_idx, self.idx_char, self.no_classes = prepare_data(text, seq_len, \n",
    "                                                                                        offset, char_idx, idx_char)\n",
    "                                                                                                      \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ''' Get the data for one training sample (by index) '''\n",
    "        return self.data[index,:,:], self.target[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' Get the number of training samples '''\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, no_classes):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.GRU(input_size = no_classes, hidden_size = args.hidden_size, num_layers = args.num_layers)\n",
    "        self.linear = nn.Linear(in_features = args.hidden_size, out_features = no_classes)\n",
    "        self.softmax = nn.Softplus()\n",
    "        \n",
    "        nn.init.normal( self.linear.weight, 0, 0.075)\n",
    "        nn.init.normal(self.linear.bias, 0, 0.075)\n",
    "        nn.init.xavier_normal(self.lstm.weight_hh_l0)\n",
    "        nn.init.xavier_normal(self.lstm.weight_ih_l0)\n",
    "        #nn.init.constant(self.lstm.bias, 0.0)\n",
    "\n",
    "        \n",
    "        # LSTM needs hidden variable which is initialized in self.init_hidden(self)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         m.weight.data.normal_(0, 0.075*0.075)\n",
    "        #         m.bias.data.normal_(0, 0.075*0.075)\n",
    "                \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        c0 = Variable(torch.zeros(args.num_layers, args.batch_size, args.hidden_size))\n",
    "        return (h0)#,c0)#Variable(torch.zeros((args.num_layers, args.batch_size, args.hidden_size)))\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        #x = x.type(torch.DoubleTensor)\n",
    "        #print(x)\n",
    "        lstm_out, hidden = self.lstm(x, hidden) # (h0, c0 are set to default values)\n",
    "        #print(lstm_out)\n",
    "        #print(\"LSTM_OUT:\")\n",
    "        #print(lstm_out)\n",
    "        #lstm_out = lstm_out.view(-1, lstm_out.size(2))\n",
    "        #print(\"----------------\")\n",
    "        #print(lstm_out)\n",
    "        linear_out = self.linear(lstm_out[-1])\n",
    "        #print(\"Linear_OUT:\")\n",
    "        #print(linear_out)\n",
    "        #res = self.softmax(linear_out) # use only the output of the last layer of lstm\n",
    "        return linear_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training loop (one epoch)\n",
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "    \n",
    "    \n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(data)\n",
    "        data = data.transpose(0, 1) #swap seq_len and batch:size\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"data:\")\n",
    "        #print(data[0, :, :])\n",
    "        \n",
    "        #print(\"output:\")\n",
    "        #print(output[0])\n",
    "        #print(\"target:\")\n",
    "        #print(target)\n",
    "        #print(\"output:\")\n",
    "        #print(output)\n",
    "        loss = 0\n",
    "        \n",
    "        for c in range(args.seq_len - 1):\n",
    "            output, hidden = model(data[c, :, :].contiguous().view(1, -1, no_classes), hidden) # // output, hidden = model(data[:, :c, :], hidden)\n",
    "            loss += criterion(output, decode(data[c+1, :, :])) # check how far away the output is from the original data\n",
    "            \n",
    "        #output, hidden = model(data, hidden)\n",
    "        #loss = criterion(output, target.type(torch.LongTensor)) # check how far away the output is from the original data\n",
    "        #print(\"loss:\")\n",
    "        #print(loss)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data[0]\n",
    "        #print(total_loss)\n",
    "\n",
    "\n",
    "    relative_loss = total_loss/float(len(train_loader))\n",
    "    print('Mean loss over epoch %s: %s' %(epoch, relative_loss))#loss.data[0]))\n",
    "    return relative_loss # return the relative loss for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation loop (one epoch)\n",
    "def evaluate(model, epoch):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss() # use the cross-entropy loss\n",
    "    total_loss = 0.0 # compute total loss over one epoch\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        #print(data)\n",
    "        data = data.transpose(0, 1)\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output, target.type(torch.LongTensor)) # check how far away the output is from the original data\n",
    "\n",
    "        total_loss += loss.data[0]\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    relative_loss = total_loss/float(len(train_loader))\n",
    "    print('Mean test loss over epoch %s: %s' %(epoch, relative_loss))#loss.data[0]))\n",
    "    return relative_loss # return the relative loss for later analysis\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction loop for ONE testdata tensor\n",
    "def rnn_predict(model, testdata):\n",
    "    ''' Note: testdata have to be submitted as a tensor'''\n",
    "    testdata = torch.from_numpy(testdata)\n",
    "    #print(\"testdata:\")\n",
    "    #print(testdata)\n",
    "    model.eval()\n",
    "    #testdata = testdata.view(testdata.size(0), -1)\n",
    "    #print(\"testdata:\")\n",
    "    #print(testdata)\n",
    "    if args.cuda:\n",
    "        testdata = testdata.cuda()\n",
    "    testdata = testdata.type(torch.FloatTensor)\n",
    "    testdata = Variable(testdata)\n",
    "    hidden = model.init_hidden()\n",
    "    prediction = model(testdata.unsqueeze(1), hidden)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Function that returns the largest factor of number that isn't the number itself '''\n",
    "def lfactor(num):\n",
    "    for i in range(num - 1, 0, -1): # go backwards from num - 1 to 1\n",
    "        if num % i == 0:            # if a number divides evenly\n",
    "            return i                # it's the largest factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marvins test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# die funktion brauchen wir vllt gar nicht, je nachdem ob wir den test loader verwenden oder wie wir das auch immer machen\n",
    "def prepare_input(text):\n",
    "    X = np.zeros((args.seq_len, no_classes))  # array with one entry which have 20 lines, each 11 entrys\n",
    "    offset = 0\n",
    "    if len(text)<args.seq_len:\n",
    "        offset = args.seq_len-len(text)\n",
    "    for t, char in enumerate(text):          \n",
    "        X[t+offset, char_idx[char]] = 1.\n",
    "    return X\n",
    "\n",
    "def sample(preds, top_n=1):\n",
    "    #print(\"test\")\n",
    "    preds = preds[-1].data.numpy()\n",
    "    #print(preds)\n",
    "    #print(preds.shape)\n",
    "    #preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(len(preds), zip(preds, itertools.count()))\n",
    "\n",
    "\n",
    "def predict_completion(model, text, topn=1):\n",
    "    original_text = text\n",
    "    processed = text\n",
    " \n",
    "    #print(len(processed))\n",
    "    max_iterations = 10\n",
    "    i = 0\n",
    "    completion = ''\n",
    "    next_char = '' # init\n",
    "    while next_char != ' ' and i < max_iterations:\n",
    "        i += 1\n",
    "        x = prepare_input(text)\n",
    "        preds = rnn_predict(model, x)\n",
    "        next_chars = sample(preds[0], top_n=topn)\n",
    "        #print('id, char: ' + str(next_chars[0][1]) + ', ' + str(idx_char[next_chars[0][1]]))\n",
    "        text = text[1:] + idx_char[next_chars[0][1]]\n",
    "        completion += idx_char[next_chars[0][1]]\n",
    "        next_char = idx_char[next_chars[0][1]]\n",
    "\n",
    "    return completion\n",
    "\n",
    "\n",
    "def predict_completions(model, text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.rnn_predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [idx_char[idx] + predict_completion(text[1:] + idx_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuda': False, 'seq_len': 40, 'clip': 1, 'lr': 0.1, 'offset': 1, 'batch_size': 16, 'hidden_size': 128, 'num_layers': 1}\n",
      "char_indices_map: {'v': 30, 'e': 13, 'h': 16, 'i': 17, ';': 7, 'ö': 37, 'ß': 35, 'j': 18, 'ü': 38, 'y': 33, 'o': 23, 'r': 26, '-': 1, ' ': 0, 'k': 19, 'm': 21, '9': 5, 'n': 22, '8': 4, '–': 40, '›': 44, '?': 8, 'p': 24, 'l': 20, 'g': 15, 'f': 14, '3': 3, 'c': 11, 't': 28, '1': 2, '‹': 43, 'w': 31, 'x': 32, 'd': 12, 'a': 9, 'z': 34, 's': 27, 'ä': 36, '…': 42, 'u': 29, '‘': 41, 'b': 10, ':': 6, 'ā': 39, 'q': 25}\n",
      "len(char_indices_map): 45\n",
      "nr training samples 15980\n",
      "nr training samples 15980\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.txt'\n",
    "args = {}\n",
    "args = set_config(config_path, args)\n",
    "print(args)\n",
    "\n",
    "# get whole text to generate char indices map and vice versa\n",
    "text = prepare_text('./brown.txt')\n",
    "# Get all the unique characters appearing in the text \n",
    "chars = sorted(list(set(text)))\n",
    "char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "print('char_indices_map: ' + str(char_idx))\n",
    "print('len(char_indices_map): ' + str(len(char_idx)))\n",
    "idx_char = dict((i, c) for i, c in enumerate(chars)) #### das brauchen wir später!!!\n",
    "no_classes = len(chars) # the nr. of unique characters corresponds to the nr. of classes\n",
    "\n",
    "# Generate train and test loader from our data\n",
    "train_text = prepare_text('./Brown_Leseprobe.txt')\n",
    "train_set = TextDataset(train_text, args.seq_len, args.offset, char_idx, idx_char)\n",
    "#args.batch_size = lfactor(len(train_set))\n",
    "train_loader = DataLoader(train_set, batch_size = args.batch_size, shuffle=True)\n",
    "\n",
    "# set further parameters\n",
    "char_idx = train_set.char_idx\n",
    "idx_char = train_set.idx_char\n",
    "no_classes = train_set.no_classes\n",
    "input_shape = (args.seq_len, no_classes) # seq_len * nr. of unique characters \n",
    "\n",
    "def dim(a):\n",
    "    if not type(a) == list:\n",
    "        return []\n",
    "    return [len(a)] + dim(a[0])\n",
    "\n",
    "# for i, val in enumerate(train_loader):\n",
    "#     print(val)\n",
    "#     if i==1:\n",
    "#         break\n",
    "\n",
    "test_text = prepare_text('./Brown_Leseprobe_test.txt')\n",
    "test_set = TextDataset(test_text, args.seq_len, args.offset, char_idx, idx_char)\n",
    "test_loader = DataLoader(test_set, batch_size = args.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# get len of data to determine the possible batch_size\n",
    "print(args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 45)\n",
      "LSTM_RNN(\n",
      "  (lstm): GRU(45, 128)\n",
      "  (linear): Linear(in_features=128, out_features=45)\n",
      "  (softmax): Softplus(beta=1, threshold=20)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "print(input_shape)\n",
    "rnn = LSTM_RNN(no_classes)\n",
    "if args.cuda:\n",
    "    rnn.cuda()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rnn = torch.load(\"GRU-SoftPlus-epoch#6.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the optimization algorithm\n",
    "optimizer = optim.Adam(rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findOnes(sample):\n",
    "    arr = sample.data.numpy()\n",
    "    i = 0\n",
    "    for k in np.nditer(arr):\n",
    "        if k == 1:\n",
    "            break\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "def decode(data):\n",
    "    class_tensor = torch.FloatTensor(args.batch_size)\n",
    "    for i in range(args.batch_size):\n",
    "        class_tensor[i] = findOnes(data[i])\n",
    "    \n",
    "    return Variabelclass_tensor\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19\n",
      " 17\n",
      " 20\n",
      " 29\n",
      " 27\n",
      " 13\n",
      " 20\n",
      " 28\n",
      " 38\n",
      "  0\n",
      " 27\n",
      " 13\n",
      " 22\n",
      " 22\n",
      "  0\n",
      " 13\n",
      "[torch.FloatTensor of size 16]\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.FloatTensor' object has no attribute 'requires_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-783607bbfd6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#history['acc_test'] = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#loss_test = evaluate(rnn, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ad7617902714>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# // output, hidden = model(data[:, :c, :], hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# check how far away the output is from the original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#output, hidden = model(data, hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[1;32m    601\u001b[0m                                self.ignore_index, self.reduce)\n",
      "\u001b[0;32m/home/marvin/anaconda3/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m_assert_no_grad\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"nn criterions don't compute the gradient w.r.t. targets - please \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"mark these variables as volatile or not requiring gradients\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.FloatTensor' object has no attribute 'requires_grad'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run training and store history\n",
    "history = dict()\n",
    "history['loss_train'] = []\n",
    "history['loss_test'] = []\n",
    "\n",
    "# wie wir die accuracy machen, weiß ich noch nicht...\n",
    "#history['acc_train'] = []\n",
    "#history['acc_test'] = []\n",
    "for epoch in range(10):\n",
    "    loss_train = train(rnn, epoch)\n",
    "    #loss_test = evaluate(rnn, epoch)\n",
    "    history['loss_train'].append(loss_train)\n",
    "    #history['loss_test'].append(loss_test)\n",
    "    #torch.save(rnn, 'GRU-epoch#{}.pt'.format(epoch))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGHCAYAAABSw0P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79ed4549b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.save(rnn, 'GRU-SoftPlus-best.pt')\n",
    "\n",
    "def plotLineData(header, yLabel, firstData, firstLabel, firstColor='b', xLabel='epoch'):\n",
    "    plt.plot(firstData, color=firstColor)\n",
    "    plt.title(header)\n",
    "    plt.ylabel(yLabel)\n",
    "    plt.xlabel(xLabel)\n",
    "    plt.legend([firstLabel], loc='upper right')\n",
    "    plt.savefig(\"loss_train_GRU.png\")\n",
    "    plt.show()\n",
    "plotLineData(\"Loss\", \"loss\", history['loss_train'], \"loss\")\n",
    "# Try a prediction\n",
    "\n",
    "#testdata = Variable(torch.from_numpy(test_set.data[0])) # get first element from the test set\n",
    "#truth = test_set.target[0]\n",
    "#print(testdata,truth)\n",
    "\n",
    "#prediction = rnn(testdata)\n",
    "## dann muss man hier noch auf die sizes achten, ach verdammt\n",
    "#prepare_input(\"This is an example of input for our LSTM\".lower(), train_set.data, char_idx)\n",
    "#print(predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahrt \n",
      "h \n",
      "ir \n",
      "ten \n",
      "nen \n",
      "elt \n",
      "n \n",
      "eifen \n",
      "eichten \n",
      "en \n",
      "en \n"
     ]
    }
   ],
   "source": [
    "# num_layers = 3 #6\n",
    "testcases = [\"rfolge kleiner Eruptionen in heftige Bew\", \"während die historische zahnradbahn sic\", \n",
    "             \"hrend die historische zahnradbahn sich m\", \"nd die historische zahnradbahn sich mühs\", \n",
    "             \"e historische zahnradbahn sich mühsam ih\", \"torische zahnradbahn sich mühsam ihren w\", \n",
    "             \"che zahnradbahn sich mühsam ihren weg de\", \"hnradbahn sich mühsam ihren weg den schw\", \n",
    "             \"n sich mühsam ihren weg den schwindelerr\", \"am ihren weg den schwindelerregend steil\",\n",
    "             \"hwindelerregend steilen hang hinaufkrall\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len \n",
      "en \n",
      "ebeten \n",
      "en \n",
      "ien \n",
      "recht \n",
      "den \n",
      "uklichte \n",
      "en \n",
      " \n",
      "chten \n"
     ]
    }
   ],
   "source": [
    "# GRU #6\n",
    "testcases = [\"mühsam ihren Weg den schwindel\", \"hen Außenhaut der reptilienart\", \n",
    "             \"chien das weitläufige Klosterg\", \" flanke einer senkrecht aufrag\", \n",
    "             \"irsch auf die gezackten bergsp\", \"ebaut in die flanke einer senk\", \n",
    "             \"in den bergen und andere unbil\", \"hner vor der modernen welt abz\", \n",
    "             \"egend steilen Hang hinaufkrall\", \"uf magische Weise von der fels\",\n",
    "             \"den des Wetters und der Geschi\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "er \n",
      "en \n",
      "ebäude \n",
      "enden \n",
      "itsen \n",
      "erechittsg\n",
      "den \n",
      "ahinischen\n",
      "te \n",
      "e \n",
      "chtte \n"
     ]
    }
   ],
   "source": [
    "# num_layers = 3 #5\n",
    "testcases = [\"mühsam ihren Weg den schwindel\", \"hen Außenhaut der reptilienart\", \n",
    "             \"chien das weitläufige Klosterg\", \" flanke einer senkrecht aufrag\", \n",
    "             \"irsch auf die gezackten bergsp\", \"ebaut in die flanke einer senk\", \n",
    "             \"in den bergen und andere unbil\", \"hner vor der modernen welt abz\", \n",
    "             \"egend steilen Hang hinaufkrall\", \"uf magische Weise von der fels\",\n",
    "             \"den des Wetters und der Geschi\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cher \n",
      "dere \n",
      "genden \n",
      "er \n",
      "llte \n",
      "itzen \n",
      "ukommen \n",
      "uschotten \n"
     ]
    }
   ],
   "source": [
    "# GRU #7\n",
    "testcases = [\"Während die historis\", \"ihren Weg den schwin\", \n",
    "             \"iner senkrecht aufra\", \"re Unbilden des Wett\", \n",
    "             \"eilen Hang hinaufkra\", \"die gezackten Bergsp\", \n",
    "             \"ichen Bestimmung abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chen \n",
      "tent \n",
      "genden \n",
      "ert \n",
      "gen \n",
      "itsen \n",
      "lrechen \n",
      "ahinischen\n"
     ]
    }
   ],
   "source": [
    "# num_layers = 3 #2\n",
    "testcases = [\"Während die historis\", \"ihren Weg den schwin\", \n",
    "             \"iner senkrecht aufra\", \"re Unbilden des Wett\", \n",
    "             \"eilen Hang hinaufkra\", \"die gezackten Bergsp\", \n",
    "             \"ichen Bestimmung abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che \n",
      "eiten \n",
      "n \n",
      "rochen \n",
      "en \n",
      "f \n",
      "n \n",
      "en \n",
      "und \n",
      "uklichte \n"
     ]
    }
   ],
   "source": [
    "# Softplus #5\n",
    "testcases = [\"historis\", \"schw\", \"Garte\", \"senk\", \"Wett\",\n",
    "             \"hinau\", \"die gezackte\", \"Klos\",\n",
    "             \"abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chen \n",
      "issen \n",
      "n \n",
      "eit \n",
      "e \n",
      "f \n",
      "n \n",
      "ten \n",
      "u \n",
      "uscholt \n"
     ]
    }
   ],
   "source": [
    "# GRU #5\n",
    "testcases = [\"historis\", \"schw\", \"Garte\", \"senk\", \"Wett\",\n",
    "             \"hinau\", \"die gezackte\", \"Klos\",\n",
    "             \"abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t \n",
      "and \n",
      "n \n",
      "en \n",
      "en \n",
      "nd \n",
      "n \n",
      "ud \n",
      "ahinischen\n"
     ]
    }
   ],
   "source": [
    "# num_layers = 3 #4\n",
    "testcases = [\"historis\", \"schw\", \"Garte\", \"senkrech\", \"Wett\",\n",
    "             \"hinau\", \"die gezackte\", \n",
    "             \"abz\", \"er modernen Welt abz\"]\n",
    "for case in testcases:\n",
    "    print(predict_completion(rnn, case.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "{' ': 0, '!': 1, '*': 2, '-': 3, '1': 4, '3': 5, '7': 6, '8': 7, '9': 8, ':': 9, ';': 10, '?': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37, 'ß': 38, 'ä': 39, 'ó': 40, 'ö': 41, 'ü': 42, 'ā': 43, '–': 44, '‘': 45, '’': 46, '…': 47, '‹': 48, '›': 49}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(train_set.no_classes)\n",
    "print(char_idx)\n",
    "print(args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
